# üß† Por Que Claude Inventa Dados?

## üîç An√°lise T√©cnica do Comportamento

### 1. **Conflito entre Conhecimento Pr√©-treinado e Dados Fornecidos**

Claude foi treinado com BILH√ïES de exemplos que incluem:
- Informa√ß√µes sobre empresas brasileiras (Makro, Walmart, Extra)
- Padr√µes de resposta "completos" e "√∫teis"
- Tend√™ncia a fornecer respostas detalhadas

Quando recebe dados parciais, o modelo:
```
Dados fornecidos: 78 clientes em 933 registros
Conhecimento interno: "Sistemas de frete atendem centenas de clientes"
Resultado: Tenta "completar" a resposta com conhecimento geral
```

### 2. **Press√£o para Ser √ötil (Helpfulness Bias)**

O modelo foi treinado para:
- ‚úÖ Ser √∫til e informativo
- ‚úÖ Fornecer respostas completas
- ‚ùå Mas isso conflita com "usar apenas dados fornecidos"

Exemplo:
```
Pergunta: "Quais s√£o os principais clientes?"
Dados: ATACADAO, ASSAI, TOTAL ATACADO
Impulso: "Essa lista parece incompleta, vou adicionar outros varejistas conhecidos"
```

### 3. **Problema de Continuidade de Contexto**

Mesmo ap√≥s corre√ß√£o, Claude n√£o mant√©m a restri√ß√£o:

```python
Turno 1: Inventa dados
Turno 2: "Desculpe, vou usar apenas dados reais"
Turno 3: Inventa dados novamente
```

Por qu√™? Cada resposta √© gerada considerando:
- System prompt (instru√ß√µes gerais)
- Hist√≥rico da conversa
- **MAS** o impulso de ser √∫til √© mais forte que a corre√ß√£o anterior

### 4. **Embeddings e Associa√ß√µes Sem√¢nticas**

No espa√ßo de embeddings do modelo:
- "ATACAD√ÉO" est√° pr√≥ximo de "MAKRO", "WALMART", "EXTRA"
- S√£o todos "grandes varejistas brasileiros"
- O modelo faz associa√ß√µes autom√°ticas

```
Entrada: "clientes do sistema de frete" + "ATACAD√ÉO"
Ativa√ß√£o: neur√¥nios relacionados a "varejo brasileiro"
Sa√≠da: lista expandida com empresas similares
```

### 5. **Temperature e Sampling**

Mesmo com temperature baixa (0.1), o modelo ainda:
- Tem probabilidades n√£o-zero para tokens de empresas conhecidas
- Pode amostrar esses tokens durante a gera√ß√£o

### 6. **Falta de Grounding Expl√≠cito**

O modelo n√£o tem um mecanismo de "grounding" que:
- Verifique cada afirma√ß√£o contra os dados
- Bloqueie tokens n√£o presentes nos dados
- Force ader√™ncia estrita aos fatos fornecidos

## üí° Por Isso as Corre√ß√µes S√£o Necess√°rias

### Script 1: `corrigir_claude_inventando_dados.py`
- Adiciona regras expl√≠citas no system prompt
- Detecta quando pergunta √© sobre totais
- Implementa queries especiais sem filtro

### Script 2: `corrigir_claude_forcando_dados_reais.py`
- System prompt AGRESSIVO
- Lista de empresas BANIDAS hardcoded
- Validador que detecta e avisa sobre inven√ß√µes
- Inclui lista de clientes reais no prompt

## üéØ Solu√ß√£o Ideal (Futura)

O ideal seria implementar:

1. **Constrained Generation**: Limitar tokens poss√≠veis baseado nos dados
2. **Fact Checking Layer**: Validar cada afirma√ß√£o antes de incluir
3. **Retrieval-Augmented Generation**: Buscar apenas nos dados fornecidos
4. **Fine-tuning**: Treinar o modelo especificamente para n√£o inventar

## üìä Resumo

Claude inventa porque:
- Tem conhecimento interno sobre empresas brasileiras
- Foi treinado para ser √∫til e completo
- Associa√ß√µes sem√¢nticas ativam empresas relacionadas
- N√£o tem mecanismo de grounding estrito
- Cada resposta √© gerada semi-independentemente

As corre√ß√µes propostas for√ßam o modelo a aderir aos dados atrav√©s de:
- Instru√ß√µes expl√≠citas e repetitivas
- Valida√ß√£o p√≥s-gera√ß√£o
- Inclus√£o dos dados reais no prompt
- Proibi√ß√µes espec√≠ficas 