#!/usr/bin/env python3
"""
üß™ TESTE DOS SISTEMAS CLAUDE AI ATIVADOS
Valida se todos os sistemas est√£o funcionando corretamente
"""

import os
import sys
import json
import logging
from pathlib import Path
from datetime import datetime

# Configurar logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('teste_sistemas_claude.log')
    ]
)
logger = logging.getLogger(__name__)

class TestadorSistemasClaudeAI:
    """Classe para testar todos os sistemas Claude AI"""
    
    def __init__(self):
        self.resultados = {}
        self.erros = []
        
    def executar_todos_os_testes(self):
        """Executa todos os testes dispon√≠veis"""
        logger.info("üß™ INICIANDO TESTES DOS SISTEMAS CLAUDE AI")
        logger.info("=" * 60)
        
        testes = [
            ("Security Guard", self.teste_security_guard),
            ("Lifelong Learning", self.teste_lifelong_learning),
            ("Auto Command Processor", self.teste_auto_command_processor),
            ("Code Generator", self.teste_code_generator),
            ("Project Scanner", self.teste_project_scanner),
            ("Sistema Real Data", self.teste_sistema_real_data),
            ("Integra√ß√£o Completa", self.teste_integracao_completa),
            ("Performance", self.teste_performance),
            ("Logs e Configura√ß√µes", self.teste_logs_configs)
        ]
        
        sucessos = 0
        
        for i, (nome, teste_func) in enumerate(testes, 1):
            logger.info(f"\n[{i}/{len(testes)}] Testando {nome}...")
            try:
                resultado = teste_func()
                self.resultados[nome] = resultado
                if resultado['sucesso']:
                    sucessos += 1
                    logger.info(f"‚úÖ {nome} - SUCESSO")
                else:
                    logger.error(f"‚ùå {nome} - FALHOU: {resultado.get('erro', 'Erro desconhecido')}")
            except Exception as e:
                logger.error(f"‚ùå {nome} - ERRO CR√çTICO: {e}")
                self.resultados[nome] = {'sucesso': False, 'erro': str(e)}
                self.erros.append(f"{nome}: {e}")
        
        # Relat√≥rio final
        self.gerar_relatorio_final(sucessos, len(testes))
        
        return sucessos >= len(testes) * 0.8  # 80% de sucesso
    
    def teste_security_guard(self):
        """Testa o Security Guard"""
        try:
            from app.claude_ai.security_guard import ClaudeSecurityGuard
            security = ClaudeSecurityGuard()
            
            # Testar valida√ß√£o
            allowed, reason, _ = security.validate_file_operation(
                "app/teste.py", "CREATE", "print('teste')"
            )
            
            logger.info(f"‚úÖ Security Guard funcionando - Valida√ß√£o: {allowed or 'PENDENTE' in reason}")
            return True
        except Exception as e:
            logger.error(f"‚ùå Security Guard: {e}")
            return False
    
    def teste_lifelong_learning(self):
        """Testa o Lifelong Learning"""
        try:
            from app.claude_ai.lifelong_learning import LifelongLearningSystem
            lifelong = LifelongLearningSystem()
            
            stats = lifelong.obter_estatisticas_aprendizado()
            logger.info(f"‚úÖ Lifelong Learning funcionando - Stats: {len(stats)} campos")
            return True
        except Exception as e:
            logger.error(f"‚ùå Lifelong Learning: {e}")
            return False
    
    def teste_auto_command_processor(self):
        """Testa o Auto Command Processor"""
        try:
            from app.claude_ai.auto_command_processor import AutoCommandProcessor
            auto_proc = AutoCommandProcessor()
            
            comando, params = auto_proc.detect_command("crie um m√≥dulo teste")
            logger.info(f"‚úÖ Auto Command Processor funcionando - Comando: {comando}")
            return comando is not None
        except Exception as e:
            logger.error(f"‚ùå Auto Command Processor: {e}")
            return False
    
    def teste_code_generator(self):
        """Testa o Code Generator"""
        try:
            from app.claude_ai.claude_code_generator import ClaudeCodeGenerator
            code_gen = ClaudeCodeGenerator()
            
            content = code_gen.read_file("app/__init__.py")
            logger.info(f"‚úÖ Code Generator funcionando - Leu arquivo: {not content.startswith('‚ùå')}")
            return not content.startswith('‚ùå')
        except Exception as e:
            logger.error(f"‚ùå Code Generator: {e}")
            return False
    
    def teste_project_scanner(self):
        """Testa o Project Scanner"""
        try:
            from app.claude_ai.claude_project_scanner import ClaudeProjectScanner
            scanner = ClaudeProjectScanner()
            
            estrutura = scanner.discover_project_structure()
            logger.info(f"‚úÖ Project Scanner funcionando - M√≥dulos: {len(estrutura.get('modules', {}))}")
            return 'modules' in estrutura
        except Exception as e:
            logger.error(f"‚ùå Project Scanner: {e}")
            return False
    
    def teste_sistema_real_data(self):
        """Testa o Sistema Real Data"""
        try:
            from app.claude_ai.sistema_real_data import get_sistema_real_data
            
            # Teste 1: Obter dados
            dados = get_sistema_real_data()
            
            # Teste 2: Verificar estrutura
            tem_estrutura = isinstance(dados, dict) and len(dados) > 0
            
            # Teste 3: Verificar conte√∫do esperado
            campos_esperados = ['total_clientes', 'total_pedidos', 'total_embarques']
            campos_encontrados = sum(1 for campo in campos_esperados if campo in str(dados))
            
            detalhes = {
                'dados_obtidos': dados is not None,
                'estrutura_valida': tem_estrutura,
                'tamanho_dados': len(str(dados)) if dados else 0,
                'campos_encontrados': campos_encontrados,
                'campos_esperados': len(campos_esperados)
            }
            
            return {
                'sucesso': tem_estrutura and campos_encontrados > 0,
                'detalhes': detalhes,
                'total_testes': 3,
                'testes_passaram': sum([dados is not None, tem_estrutura, campos_encontrados > 0])
            }
            
        except Exception as e:
            return {'sucesso': False, 'erro': str(e)}
    
    def teste_integracao_completa(self):
        """Testa a integra√ß√£o entre sistemas"""
        try:
            # Teste 1: Importa√ß√µes funcionam
            sistemas_importados = 0
            sistemas_testados = [
                'app.claude_ai.security_guard',
                'app.claude_ai.lifelong_learning',
                'app.claude_ai.auto_command_processor',
                'app.claude_ai.claude_code_generator',
                'app.claude_ai.claude_project_scanner'
            ]
            
            for sistema in sistemas_testados:
                try:
                    __import__(sistema)
                    sistemas_importados += 1
                except:
                    pass
            
            # Teste 2: Inicializa√ß√£o conjunta
            try:
                from app.claude_ai import setup_claude_ai
                from app import create_app
                
                app = create_app()
                with app.app_context():
                    resultado_setup = setup_claude_ai(app)
                    
                setup_ok = resultado_setup is not None
            except Exception as e:
                setup_ok = False
            
            # Teste 3: Verificar __init__.py
            init_file = Path('app/claude_ai/__init__.py')
            init_existe = init_file.exists()
            
            detalhes = {
                'sistemas_importaveis': sistemas_importados,
                'total_sistemas': len(sistemas_testados),
                'setup_funciona': setup_ok,
                'init_existe': init_existe
            }
            
            return {
                'sucesso': sistemas_importados >= len(sistemas_testados) * 0.8 and setup_ok,
                'detalhes': detalhes,
                'total_testes': len(sistemas_testados) + 2,
                'testes_passaram': sistemas_importados + (1 if setup_ok else 0) + (1 if init_existe else 0)
            }
            
        except Exception as e:
            return {'sucesso': False, 'erro': str(e)}
    
    def teste_performance(self):
        """Testa performance b√°sica dos sistemas"""
        try:
            import time
            
            # Teste 1: Tempo de importa√ß√£o
            start_time = time.time()
            from app.claude_ai.claude_real_integration import ClaudeRealIntegration
            import_time = time.time() - start_time
            
            # Teste 2: Tempo de inicializa√ß√£o
            start_time = time.time()
            claude_integration = ClaudeRealIntegration()
            init_time = time.time() - start_time
            
            # Teste 3: Mem√≥ria b√°sica (arquivo de tamanho)
            arquivos_principais = [
                'app/claude_ai/claude_real_integration.py',
                'app/claude_ai/lifelong_learning.py',
                'app/claude_ai/auto_command_processor.py'
            ]
            
            tamanho_total = 0
            for arquivo in arquivos_principais:
                if Path(arquivo).exists():
                    tamanho_total += Path(arquivo).stat().st_size
            
            tamanho_mb = tamanho_total / (1024 * 1024)
            
            detalhes = {
                'tempo_importacao_ms': round(import_time * 1000, 2),
                'tempo_inicializacao_ms': round(init_time * 1000, 2),
                'tamanho_codigo_mb': round(tamanho_mb, 2),
                'performance_ok': import_time < 2.0 and init_time < 5.0
            }
            
            return {
                'sucesso': import_time < 2.0 and init_time < 5.0,  # Menos de 2s para importar, 5s para inicializar
                'detalhes': detalhes,
                'total_testes': 2,
                'testes_passaram': sum([import_time < 2.0, init_time < 5.0])
            }
            
        except Exception as e:
            return {'sucesso': False, 'erro': str(e)}
    
    def teste_logs_configs(self):
        """Testa logs e configura√ß√µes"""
        try:
            # Teste 1: Diret√≥rios existem
            diretorios_necessarios = [
                'app/claude_ai/security_configs',
                'app/claude_ai/generated_modules',
                'app/claude_ai/logs'
            ]
            
            diretorios_existem = sum(1 for d in diretorios_necessarios if Path(d).exists())
            
            # Teste 2: Arquivos de configura√ß√£o
            config_file = Path('app/claude_ai/security_configs/security_config.json')
            config_existe = config_file.exists()
            config_valido = False
            
            if config_existe:
                try:
                    with open(config_file) as f:
                        config_data = json.load(f)
                    config_valido = 'modo_seguranca' in config_data
                except:
                    pass
            
            # Teste 3: Permiss√µes de escrita
            test_log = Path('app/claude_ai/logs/test.log')
            test_log.parent.mkdir(exist_ok=True)
            
            try:
                test_log.write_text(f"Teste de escrita: {datetime.now()}")
                escrita_ok = test_log.exists()
                test_log.unlink()  # Limpar
            except:
                escrita_ok = False
            
            detalhes = {
                'diretorios_criados': diretorios_existem,
                'total_diretorios': len(diretorios_necessarios),
                'config_existe': config_existe,
                'config_valido': config_valido,
                'permissao_escrita': escrita_ok
            }
            
            testes_passaram = [
                diretorios_existem == len(diretorios_necessarios),
                config_existe,
                config_valido,
                escrita_ok
            ]
            
            return {
                'sucesso': sum(testes_passaram) >= 3,  # Pelo menos 3 de 4
                'detalhes': detalhes,
                'total_testes': len(testes_passaram),
                'testes_passaram': sum(testes_passaram)
            }
            
        except Exception as e:
            return {'sucesso': False, 'erro': str(e)}
    
    def gerar_relatorio_final(self, sucessos, total):
        """Gera relat√≥rio final dos testes"""
        logger.info("\n" + "=" * 60)
        logger.info("üìä RELAT√ìRIO FINAL DOS TESTES")
        logger.info("=" * 60)
        
        percentual = (sucessos / total) * 100
        logger.info(f"üéØ RESULTADO GERAL: {sucessos}/{total} testes passaram ({percentual:.1f}%)")
        
        if percentual >= 90:
            logger.info("üöÄ EXCELENTE! Todos os sistemas est√£o funcionando perfeitamente!")
        elif percentual >= 75:
            logger.info("‚úÖ MUITO BOM! A maioria dos sistemas est√° funcionando.")
        elif percentual >= 50:
            logger.info("‚ö†Ô∏è PARCIAL. Alguns sistemas precisam de aten√ß√£o.")
        else:
            logger.info("‚ùå CR√çTICO. Muitos sistemas n√£o est√£o funcionando.")
        
        logger.info("\nüìã DETALHES POR SISTEMA:")
        for nome, resultado in self.resultados.items():
            status = "‚úÖ" if resultado.get('sucesso') else "‚ùå"
            detalhes = resultado.get('detalhes', {})
            
            logger.info(f"{status} {nome}:")
            if resultado.get('sucesso'):
                total_testes = resultado.get('total_testes', 0)
                passaram = resultado.get('testes_passaram', 0)
                logger.info(f"   üî¨ {passaram}/{total_testes} testes internos passaram")
            else:
                erro = resultado.get('erro', 'Erro desconhecido')
                logger.info(f"   ‚ùå {erro}")
        
        if self.erros:
            logger.info("\nüö® ERROS ENCONTRADOS:")
            for erro in self.erros:
                logger.info(f"   ‚Ä¢ {erro}")
        
        logger.info("\nüìÅ ARQUIVOS DE LOG:")
        logger.info(f"   ‚Ä¢ teste_sistemas_claude.log")
        logger.info(f"   ‚Ä¢ app/claude_ai/logs/ (se existir)")
        
        if percentual >= 75:
            logger.info("\nüéâ SISTEMAS CLAUDE AI FUNCIONANDO!")
            logger.info("üîÑ Pr√≥ximos passos:")
            logger.info("   1. Reiniciar aplica√ß√£o Flask")
            logger.info("   2. Testar comandos no chat:")
            logger.info("      ‚Ä¢ 'crie um m√≥dulo vendas'")
            logger.info("      ‚Ä¢ 'descubra a estrutura do projeto'")
            logger.info("      ‚Ä¢ 'o que voc√™ aprendeu?'")
        else:
            logger.info("\n‚ö° A√á√ÉO NECESS√ÅRIA:")
            logger.info("   1. Revisar erros acima")
            logger.info("   2. Executar 'python ativar_sistemas_claude.py' novamente")
            logger.info("   3. Verificar depend√™ncias e permiss√µes")

def main():
    """Fun√ß√£o principal"""
    logger.info("üß™ INICIANDO TESTES COMPLETOS DOS SISTEMAS CLAUDE AI")
    
    testador = TestadorSistemasClaudeAI()
    sucesso_geral = testador.executar_todos_os_testes()
    
    return sucesso_geral

if __name__ == '__main__':
    try:
        sucesso = main()
        exit(0 if sucesso else 1)
    except KeyboardInterrupt:
        logger.info("\n‚ö†Ô∏è Testes cancelados pelo usu√°rio")
        exit(1)
    except Exception as e:
        logger.error(f"\n‚ùå Erro fatal nos testes: {e}")
        exit(1) 