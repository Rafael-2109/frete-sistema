"""
Utilit√°rios para opera√ß√µes de banco de dados com tratamento de erros e retry logic
"""
import time
import logging
from functools import wraps
from sqlalchemy.exc import OperationalError, DBAPIError, DisconnectionError
from sqlalchemy import create_engine, pool
from flask import current_app

logger = logging.getLogger(__name__)

def retry_on_ssl_error(max_retries=3, backoff_factor=1.0):
    """
    Decorator para retry autom√°tico em caso de erro SSL/conex√£o
    
    Args:
        max_retries: N√∫mero m√°ximo de tentativas
        backoff_factor: Fator de multiplica√ß√£o para o tempo de espera entre tentativas
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                    
                except (OperationalError, DBAPIError, DisconnectionError) as e:
                    last_exception = e
                    error_msg = str(e)
                    
                    # Verificar se √© erro de SSL ou conex√£o
                    if any(err in error_msg.lower() for err in ['ssl', 'connection', 'closed', 'timeout']):
                        if attempt < max_retries - 1:
                            wait_time = backoff_factor * (2 ** attempt)
                            logger.warning(f"‚ö†Ô∏è Erro de conex√£o (tentativa {attempt + 1}/{max_retries}). "
                                         f"Aguardando {wait_time}s antes de tentar novamente...")
                            
                            # Tentar fazer rollback se poss√≠vel
                            try:
                                from app import db
                                db.session.rollback()
                                # For√ßar reconex√£o
                                db.session.close()
                                db.engine.dispose()
                            except Exception as e:
                                pass
                            
                            time.sleep(wait_time)
                        else:
                            logger.error(f"‚ùå Erro persistente ap√≥s {max_retries} tentativas: {e}")
                            raise
                    else:
                        # N√£o √© erro de conex√£o, propagar imediatamente
                        raise
                        
                except Exception as e:
                    # Outros erros n√£o relacionados a conex√£o
                    logger.error(f"‚ùå Erro n√£o relacionado a conex√£o: {e}")
                    raise
            
            # Se chegou aqui, todas as tentativas falharam
            if last_exception:
                raise last_exception
                
        return wrapper
    return decorator


def execute_in_chunks(query_func, items, chunk_size=100, description="items"):
    """
    Executa uma fun√ß√£o de query em chunks para evitar timeout
    
    Args:
        query_func: Fun√ß√£o que recebe uma lista de items e retorna resultados
        items: Lista de items para processar
        chunk_size: Tamanho de cada chunk
        description: Descri√ß√£o para logging
        
    Returns:
        Lista com todos os resultados concatenados
    """
    if not items:
        return []
    
    total_items = len(items)
    results = []
    
    logger.info(f"üì¶ Processando {total_items} {description} em lotes de {chunk_size}...")
    
    for i in range(0, total_items, chunk_size):
        chunk = items[i:i + chunk_size]
        chunk_num = (i // chunk_size) + 1
        total_chunks = (total_items + chunk_size - 1) // chunk_size
        
        try:
            logger.debug(f"   Processando lote {chunk_num}/{total_chunks} ({len(chunk)} items)...")
            chunk_results = query_func(chunk)
            results.extend(chunk_results if chunk_results else [])
            
            # Pequena pausa entre chunks para n√£o sobrecarregar
            if i + chunk_size < total_items:
                time.sleep(0.1)
                
        except Exception as e:
            logger.error(f"‚ùå Erro ao processar lote {chunk_num}: {e}")
            # Continuar com os pr√≥ximos chunks mesmo se um falhar
            continue
    
    logger.info(f"‚úÖ {len(results)} resultados obtidos de {total_items} {description}")
    return results


def safe_db_operation(operation_func, *args, **kwargs):
    """
    Executa uma opera√ß√£o de banco de dados com tratamento de erros e retry
    
    Args:
        operation_func: Fun√ß√£o a ser executada
        *args, **kwargs: Argumentos para a fun√ß√£o
        
    Returns:
        Resultado da opera√ß√£o ou None em caso de erro
    """
    try:
        return retry_on_ssl_error()(operation_func)(*args, **kwargs)
    except Exception as e:
        logger.error(f"‚ùå Erro na opera√ß√£o de banco de dados: {e}")
        return None


def ensure_connection():
    """
    Garante que a conex√£o com o banco est√° ativa
    """
    try:
        from app import db
        from sqlalchemy import text
        
        # Testa a conex√£o
        db.session.execute(text('SELECT 1'))
        return True
        
    except (OperationalError, DBAPIError, DisconnectionError) as e:
        logger.warning(f"‚ö†Ô∏è Conex√£o perdida, tentando reconectar: {e}")
        
        try:
            # Fechar sess√£o atual
            db.session.rollback()
            db.session.close()
            
            # Descartar pool de conex√µes
            db.engine.dispose()
            
            # Testar nova conex√£o
            db.session.execute(text('SELECT 1'))
            logger.info("‚úÖ Conex√£o restabelecida com sucesso")
            return True
            
        except Exception as reconnect_error:
            logger.error(f"‚ùå Falha ao reconectar: {reconnect_error}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Erro inesperado ao verificar conex√£o: {e}")
        return False


def create_resilient_engine(database_url=None):
    """
    Cria um engine SQLAlchemy com configura√ß√µes otimizadas para resili√™ncia
    
    Args:
        database_url: URL do banco de dados (usa a configura√ß√£o padr√£o se n√£o fornecida)
        
    Returns:
        Engine SQLAlchemy configurado
    """
    if not database_url:
        database_url = current_app.config.get('SQLALCHEMY_DATABASE_URI')
    
    # Configura√ß√µes otimizadas para evitar timeout e erros SSL
    engine = create_engine(
        database_url,
        poolclass=pool.QueuePool,
        pool_size=10,                    # Tamanho do pool
        max_overflow=20,                 # Conex√µes extras permitidas
        pool_timeout=30,                 # Timeout para obter conex√£o do pool
        pool_recycle=3600,              # Reciclar conex√µes ap√≥s 1 hora
        pool_pre_ping=True,             # Testar conex√£o antes de usar
        connect_args={
            'connect_timeout': 30,       # Timeout de conex√£o
            'keepalives': 1,            # Ativar keepalive
            'keepalives_idle': 30,      # Tempo idle antes do keepalive
            'keepalives_interval': 10,   # Intervalo entre keepalives
            'keepalives_count': 5        # N√∫mero de keepalives antes de desistir
        }
    )
    
    return engine