#!/usr/bin/env python3
"""
üöÄ INTEGRA√á√ÉO CLAUDE MELHORADA - Entendimento Inteligente do Usu√°rio
Combina Claude 4 Sonnet com an√°lise inteligente de consultas para respostas mais precisas
"""

import os
import anthropic
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import json

import logging
from .intelligent_query_analyzer import get_intelligent_analyzer, TipoInformacao, UrgenciaConsulta
from .claude_real_integration import ClaudeRealIntegration
from .sistema_real_data import get_sistema_real_data

logger = logging.getLogger(__name__)

class EnhancedClaudeIntegration:
    """
    üöÄ Integra√ß√£o Claude Melhorada com Entendimento Inteligente
    
    Funcionalidades:
    - An√°lise inteligente de consultas antes de enviar ao Claude
    - Otimiza√ß√£o autom√°tica de prompts
    - Detec√ß√£o de ambiguidades e sugest√µes de esclarecimento
    - Contextualiza√ß√£o inteligente baseada na inten√ß√£o
    - Respostas mais precisas e coerentes
    """
    
    def __init__(self):
        """Inicializa a integra√ß√£o Claude melhorada"""
        self.claude_integration = ClaudeRealIntegration()
        self.intelligent_analyzer = get_intelligent_analyzer()
        self.sistema_data = get_sistema_real_data()
        
        logger.info("üöÄ Integra√ß√£o Claude Melhorada inicializada com IA de entendimento")
    
    def processar_consulta_inteligente(self, consulta: str, user_context: Dict = None) -> Dict[str, Any]:
        """
        Processa consulta com an√°lise inteligente ANTES de enviar ao Claude
        
        Args:
            consulta: Consulta em linguagem natural
            user_context: Contexto do usu√°rio
            
        Returns:
            Resposta completa com an√°lise + resposta Claude
        """
        
        logger.info(f"üöÄ Processando consulta inteligente: '{consulta[:50]}...'")
        
        # 1. AN√ÅLISE INTELIGENTE DA CONSULTA
        interpretacao = self.intelligent_analyzer.analisar_consulta_inteligente(
            consulta, user_context
        )
        
        # 2. VERIFICAR SE PRECISA DE ESCLARECIMENTO
        if interpretacao.probabilidade_interpretacao < 0.6 or interpretacao.sugestoes_esclarecimento:
            return self._gerar_resposta_esclarecimento(interpretacao)
        
        # 3. VERIFICAR URG√äNCIA CR√çTICA
        if interpretacao.urgencia == UrgenciaConsulta.CRITICA:
            return self._processar_consulta_critica(interpretacao, user_context)
        
        # 4. OTIMIZAR CONTEXTO BASEADO NA INTERPRETA√á√ÉO
        contexto_otimizado = self._otimizar_contexto_baseado_interpretacao(
            interpretacao, user_context
        )
        
        # 5. PROCESSAR COM CLAUDE USANDO PROMPT OTIMIZADO
        resposta_claude = self.claude_integration.processar_consulta_real(
            interpretacao.prompt_otimizado, contexto_otimizado
        )
        
        # 6. P√ìS-PROCESSAMENTO DA RESPOSTA
        resposta_final = self._pos_processar_resposta(
            resposta_claude, interpretacao
        )
        
        # 7. RETORNAR RESULTADO COMPLETO
        return {
            "resposta": resposta_final,
            "interpretacao": {
                "intencao": interpretacao.intencao_principal.value,
                "urgencia": interpretacao.urgencia.value,
                "entidades": interpretacao.entidades_detectadas,
                "confianca": interpretacao.probabilidade_interpretacao,
                "escopo_temporal": interpretacao.escopo_temporal
            },
            "metadados": {
                "processamento_inteligente": True,
                "tempo_processamento": datetime.now().isoformat(),
                "consultas_similares": interpretacao.consultas_similares
            }
        }
    
    def _gerar_resposta_esclarecimento(self, interpretacao) -> Dict[str, Any]:
        """Gera resposta solicitando esclarecimento quando necess√°rio"""
        
        logger.info(f"‚ùì Gerando resposta de esclarecimento (confian√ßa: {interpretacao.probabilidade_interpretacao:.2f})")
        
        resposta = "ü§î **Preciso de um esclarecimento para te ajudar melhor:**\n\n"
        
        # Mostrar o que foi entendido
        resposta += f"**O que entendi:**\n"
        resposta += f"‚Ä¢ Tipo de consulta: {interpretacao.intencao_principal.value.title()}\n"
        
        if interpretacao.entidades_detectadas["clientes"]:
            resposta += f"‚Ä¢ Cliente(s): {', '.join(interpretacao.entidades_detectadas['clientes'])}\n"
        
        if interpretacao.entidades_detectadas["localidades"]:
            resposta += f"‚Ä¢ Local: {', '.join(interpretacao.entidades_detectadas['localidades'])}\n"
        
        resposta += f"‚Ä¢ Per√≠odo: {interpretacao.escopo_temporal['descricao']}\n\n"
        
        # Adicionar sugest√µes espec√≠ficas
        if interpretacao.sugestoes_esclarecimento:
            resposta += "**Para uma resposta mais precisa:**\n"
            for sugestao in interpretacao.sugestoes_esclarecimento:
                resposta += f"‚Ä¢ {sugestao}\n"
            resposta += "\n"
        
        # Sugerir consultas similares
        if interpretacao.consultas_similares:
            resposta += "**Exemplos de consultas semelhantes:**\n"
            for exemplo in interpretacao.consultas_similares:
                resposta += f"‚Ä¢ \"{exemplo}\"\n"
        
        resposta += "\nüí° **Reformule sua pergunta com mais detalhes e eu terei uma resposta precisa para voc√™!**"
        
        return {
            "resposta": resposta,
            "interpretacao": {
                "status": "esclarecimento_necessario",
                "confianca": interpretacao.probabilidade_interpretacao,
                "sugestoes": interpretacao.sugestoes_esclarecimento
            },
            "metadados": {
                "requer_esclarecimento": True,
                "consultas_similares": interpretacao.consultas_similares
            }
        }
    
    def _processar_consulta_critica(self, interpretacao, user_context: Dict) -> Dict[str, Any]:
        """Processa consultas cr√≠ticas com prioridade m√°xima"""
        
        logger.warning(f"üö® Processando consulta CR√çTICA: {interpretacao.consulta_original}")
        
        # Prompt especializado para emerg√™ncias
        prompt_critico = f"""
üö® CONSULTA CR√çTICA DETECTADA üö®

CONSULTA DO USU√ÅRIO: {interpretacao.consulta_original}
URG√äNCIA: M√ÅXIMA
INTEN√á√ÉO: {interpretacao.intencao_principal.value.upper()}

INSTRU√á√ïES ESPECIAIS:
1. Esta √© uma consulta de EMERG√äNCIA que requer a√ß√£o imediata
2. Priorize informa√ß√µes que ajudem a resolver o problema AGORA
3. Se h√° atrasos ou problemas, liste a√ß√µes corretivas espec√≠ficas
4. Inclua contatos/respons√°veis se necess√°rio
5. Forne√ßa timeline de resolu√ß√£o se poss√≠vel

Responda de forma DIRETA e ACION√ÅVEL:
"""
        
        resposta_claude = self.claude_integration.processar_consulta_real(
            prompt_critico, user_context
        )
        
        # Adicionar indicadores visuais de urg√™ncia
        resposta_final = f"üö® **RESPOSTA PRIORIT√ÅRIA - URG√äNCIA CR√çTICA** üö®\n\n{resposta_claude}"
        
        return {
            "resposta": resposta_final,
            "interpretacao": {
                "status": "critica",
                "urgencia": "maxima",
                "requer_acao_imediata": True
            },
            "metadados": {
                "processamento_critico": True,
                "timestamp_urgencia": datetime.now().isoformat()
            }
        }
    
    def _otimizar_contexto_baseado_interpretacao(self, interpretacao, user_context: Dict) -> Dict[str, Any]:
        """Otimiza o contexto baseado na interpreta√ß√£o inteligente"""
        
        contexto_otimizado = user_context.copy() if user_context else {}
        
        # Ajustar per√≠odo baseado na interpreta√ß√£o temporal
        if interpretacao.escopo_temporal["tipo"] != "padrao":
            contexto_otimizado["periodo_dias_override"] = interpretacao.escopo_temporal["periodo_dias"]
        
        # üè¢ INTEGRA√á√ÉO GRUPOS EMPRESARIAIS - Aplicar filtros inteligentes
        if interpretacao.entidades_detectadas.get("grupos_empresariais"):
            for grupo in interpretacao.entidades_detectadas["grupos_empresariais"]:
                logger.info(f"üè¢ Aplicando filtro de grupo empresarial: {grupo['nome']}")
                
                # Usar filtro SQL espec√≠fico do grupo detectado
                if grupo.get("filtro_sql"):
                    contexto_otimizado["filtro_cliente_sql"] = grupo["filtro_sql"]
                
                # Adicionar informa√ß√µes do grupo ao contexto para Claude
                contexto_otimizado["grupo_empresarial_detectado"] = {
                    "nome": grupo["nome"],
                    "tipo": grupo["tipo"],
                    "metodo_deteccao": grupo["metodo_deteccao"],
                    "descricao": grupo["descricao"]
                }
                
                # Se tem CNPJs espec√≠ficos, adicionar ao contexto
                if grupo.get("cnpj_prefixos"):
                    contexto_otimizado["cnpj_prefixos_grupo"] = grupo["cnpj_prefixos"]
        
        # Aplicar outros filtros detectados
        for filtro, valor in interpretacao.filtros_implicitios.items():
            contexto_otimizado[f"filtro_{filtro}"] = valor
        
        # Adicionar metadados de interpreta√ß√£o
        contexto_otimizado["interpretacao_meta"] = {
            "intencao": interpretacao.intencao_principal.value,
            "detalhamento": interpretacao.tipo_detalhamento.value,
            "entidades_detectadas": interpretacao.entidades_detectadas
        }
        
        logger.info(f"üîß Contexto otimizado baseado em interpreta√ß√£o inteligente")
        
        return contexto_otimizado
    
    def _pos_processar_resposta(self, resposta_claude: str, interpretacao) -> str:
        """P√≥s-processa a resposta do Claude baseado na interpreta√ß√£o"""
        
        resposta_processada = resposta_claude
        
        # Adicionar contexto de interpreta√ß√£o no cabe√ßalho
        cabecalho_interpretacao = self._gerar_cabecalho_interpretacao(interpretacao)
        
        # Se resposta n√£o cont√©m o cabe√ßalho Claude, adicionar nosso contexto
        if "ü§ñ **CLAUDE" not in resposta_processada:
            resposta_processada = f"{cabecalho_interpretacao}\n\n{resposta_processada}"
        else:
            # Inserir contexto antes do rodap√© do Claude
            partes = resposta_processada.split("---")
            if len(partes) >= 2:
                resposta_processada = f"{partes[0]}\n{cabecalho_interpretacao}\n\n---{partes[1]}"
        
        # Adicionar sugest√µes de consultas relacionadas se relevante
        if interpretacao.consultas_similares and interpretacao.intencao_principal == TipoInformacao.LISTAGEM:
            sugestoes_texto = "\n\nüí° **Consultas relacionadas que voc√™ pode fazer:**\n"
            for sugestao in interpretacao.consultas_similares[:3]:
                sugestoes_texto += f"‚Ä¢ \"{sugestao}\"\n"
            resposta_processada += sugestoes_texto
        
        return resposta_processada
    
    def _gerar_cabecalho_interpretacao(self, interpretacao) -> str:
        """Gera cabe√ßalho explicando a interpreta√ß√£o"""
        
        cabecalho = "üß† **INTERPRETA√á√ÉO INTELIGENTE:**\n"
        
        # Mostrar inten√ß√£o detectada
        icones_intencao = {
            TipoInformacao.LISTAGEM: "üìã",
            TipoInformacao.QUANTIDADE: "üî¢",
            TipoInformacao.VALOR: "üí∞",
            TipoInformacao.STATUS: "üìä",
            TipoInformacao.HISTORICO: "üìà",
            TipoInformacao.PROBLEMAS: "‚ö†Ô∏è",
            TipoInformacao.METRICAS: "üìä",
            TipoInformacao.DETALHAMENTO: "üîç"
        }
        
        icone = icones_intencao.get(interpretacao.intencao_principal, "üí≠")
        cabecalho += f"{icone} Consulta interpretada como: **{interpretacao.intencao_principal.value.title()}**\n"
        
        # Mostrar escopo temporal se espec√≠fico
        if interpretacao.escopo_temporal["tipo"] != "padrao":
            cabecalho += f"üìÖ Per√≠odo analisado: **{interpretacao.escopo_temporal['descricao']}**\n"
        
        # üè¢ Mostrar grupos empresariais detectados com prioridade
        if interpretacao.entidades_detectadas.get("grupos_empresariais"):
            for grupo in interpretacao.entidades_detectadas["grupos_empresariais"]:
                cabecalho += f"üè¢ **GRUPO EMPRESARIAL DETECTADO:** {grupo['nome']}\n"
                cabecalho += f"üìä Tipo: {grupo['tipo'].title()} | M√©todo: {grupo['metodo_deteccao']}\n"
        
        # Mostrar clientes individuais se n√£o h√° grupos
        elif interpretacao.entidades_detectadas.get("clientes"):
            cabecalho += f"üè¢ Cliente(s): **{', '.join(interpretacao.entidades_detectadas['clientes'])}**\n"
        
        if interpretacao.entidades_detectadas.get("localidades"):
            cabecalho += f"üó∫Ô∏è Local: **{', '.join(interpretacao.entidades_detectadas['localidades'])}**\n"
        
        # Indicador de confian√ßa
        if interpretacao.probabilidade_interpretacao >= 0.8:
            cabecalho += f"‚úÖ Confian√ßa da interpreta√ß√£o: **Alta** ({interpretacao.probabilidade_interpretacao:.0%})"
        elif interpretacao.probabilidade_interpretacao >= 0.6:
            cabecalho += f"‚ö†Ô∏è Confian√ßa da interpreta√ß√£o: **M√©dia** ({interpretacao.probabilidade_interpretacao:.0%})"
        else:
            cabecalho += f"‚ùì Confian√ßa da interpreta√ß√£o: **Baixa** ({interpretacao.probabilidade_interpretacao:.0%})"
        
        return cabecalho
    
    def validar_resposta_coerencia(self, consulta_original: str, resposta: str, interpretacao) -> Dict[str, Any]:
        """Valida se a resposta est√° coerente com a consulta original"""
        
        # An√°lise de coer√™ncia b√°sica
        coerencia = {
            "score": 0.8,  # Padr√£o
            "problemas": [],
            "sugestoes": []
        }
        
        # Verificar se resposta aborda a inten√ß√£o principal
        inten√ß√£o_keywords = {
            TipoInformacao.QUANTIDADE: ["total", "quantos", "quantidade", "n√∫mero"],
            TipoInformacao.STATUS: ["situa√ß√£o", "status", "est√°", "estado"],
            TipoInformacao.LISTAGEM: ["lista", "s√£o", "seguintes"],
            TipoInformacao.PROBLEMAS: ["problema", "atraso", "pendente", "erro"]
        }
        
        keywords_esperadas = inten√ß√£o_keywords.get(interpretacao.intencao_principal, [])
        keywords_encontradas = sum(1 for kw in keywords_esperadas if kw.lower() in resposta.lower())
        
        if keywords_encontradas == 0 and keywords_esperadas:
            coerencia["problemas"].append("Resposta pode n√£o estar abordando o tipo de informa√ß√£o solicitado")
            coerencia["score"] -= 0.2
        
        # Verificar se entidades mencionadas est√£o na resposta
        for cliente in interpretacao.entidades_detectadas.get("clientes", []):
            if cliente.lower() not in resposta.lower():
                coerencia["problemas"].append(f"Cliente '{cliente}' mencionado na consulta n√£o aparece na resposta")
                coerencia["score"] -= 0.1
        
        # Sugest√µes de melhoria
        if coerencia["score"] < 0.7:
            coerencia["sugestoes"].append("Considere reformular a consulta para ser mais espec√≠fica")
        
        return coerencia

# Inst√¢ncia global
enhanced_claude = EnhancedClaudeIntegration()

def processar_consulta_com_ia_avancada(consulta: str, user_context: Dict = None) -> str:
    """
    Fun√ß√£o principal para processar consultas com IA avan√ßada
    
    Args:
        consulta: Consulta em linguagem natural
        user_context: Contexto do usu√°rio
        
    Returns:
        Resposta processada com IA avan√ßada
    """
    
    resultado = enhanced_claude.processar_consulta_inteligente(consulta, user_context)
    
    # Se requer esclarecimento, retornar resposta de esclarecimento
    if resultado.get("metadados", {}).get("requer_esclarecimento"):
        return resultado["resposta"]
    
    # Sen√£o, retornar resposta processada normalmente
    return resultado["resposta"] 