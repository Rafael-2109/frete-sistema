"""
API Routes para an치lise de ruptura de estoque - Vers칚o Ass칤ncrona com Workers
APENAS enfileira jobs para processamento pelos workers no Render
Resultados s칚o salvos no Redis e recuperados conforme ficam prontos
"""

from flask import jsonify, request
from app.carteira.main_routes import carteira_bp
from redis import Redis
from rq import Queue
import logging
import json
import os

logger = logging.getLogger(__name__)

# Conectar ao Redis usando vari치vel de ambiente
redis_url = os.environ.get('REDIS_URL', 'redis://localhost:6379/0')
redis_conn = Redis.from_url(redis_url)
queue_atacadao = Queue('atacadao', connection=redis_conn)

# Prefixo para chaves no Redis
REDIS_PREFIX = 'ruptura:resultado:'
REDIS_TTL = 3600  # 1 hora


@carteira_bp.route('/api/ruptura/analisar-lote-async', methods=['POST'])
def analisar_ruptura_lote_async():
    """
    APENAS enfileira an치lise de ruptura para um lote de pedidos
    Workers processam e salvam no Redis
    """
    try:
        data = request.get_json()
        pedidos_ids = data.get('pedidos', [])
        tamanho_lote = data.get('tamanho_lote', 20)
        
        if not pedidos_ids:
            return jsonify({
                'success': False,
                'message': 'Lista de pedidos vazia'
            }), 400
        
        logger.info(f"游닍 Enfileirando {len(pedidos_ids)} pedidos para an치lise")
        
        # Limpar resultados antigos do Redis para estes pedidos
        for pedido_id in pedidos_ids:
            redis_conn.delete(f"{REDIS_PREFIX}{pedido_id}")
        
        # Dividir em lotes
        lotes = [pedidos_ids[i:i + tamanho_lote] 
                 for i in range(0, len(pedidos_ids), tamanho_lote)]
        
        jobs_enfileirados = 0
        
        # Enfileirar cada lote
        for i, lote in enumerate(lotes):
            logger.info(f"  Enfileirando lote {i+1}/{len(lotes)}: {len(lote)} pedidos")
            
            # Enfileirar job para o worker processar
            # O worker vai salvar os resultados no Redis
            job = queue_atacadao.enqueue(
                'app.portal.workers.ruptura_jobs.processar_lote_ruptura',
                lote,
                {'salvar_redis': True, 'redis_prefix': REDIS_PREFIX, 'redis_ttl': REDIS_TTL},
                job_timeout='10m'
            )
            
            jobs_enfileirados += 1
            logger.info(f"  Job {job.id} enfileirado")
        
        return jsonify({
            'success': True,
            'message': f'{len(pedidos_ids)} pedidos enfileirados em {jobs_enfileirados} lotes',
            'total_pedidos': len(pedidos_ids),
            'lotes_enfileirados': jobs_enfileirados
        })
        
    except Exception as e:
        logger.error(f"Erro ao enfileirar lote: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@carteira_bp.route('/api/ruptura/buscar-resultados', methods=['POST'])
def buscar_resultados_prontos():
    """
    Busca resultados que j치 foram processados e salvos no Redis
    """
    try:
        data = request.get_json()
        pedidos_ids = data.get('pedidos', [])
        
        if not pedidos_ids:
            return jsonify({
                'success': False,
                'message': 'Lista de pedidos vazia'
            }), 400
        
        resultados = {}
        pedidos_prontos = []
        pedidos_pendentes = []
        
        # Buscar cada pedido no Redis
        for pedido_id in pedidos_ids:
            chave = f"{REDIS_PREFIX}{pedido_id}"
            resultado_json = redis_conn.get(chave)
            
            if resultado_json:
                try:
                    resultado = json.loads(resultado_json)
                    resultados[pedido_id] = resultado
                    pedidos_prontos.append(pedido_id)
                except Exception as e:
                    logger.error(f"Erro ao decodificar resultado do pedido {pedido_id}: {e}")
                    pedidos_pendentes.append(pedido_id)
            else:
                pedidos_pendentes.append(pedido_id)
        
        return jsonify({
            'success': True,
            'resultados': resultados,
            'estatisticas': {
                'total_solicitados': len(pedidos_ids),
                'prontos': len(pedidos_prontos),
                'pendentes': len(pedidos_pendentes),
                'pedidos_prontos': pedidos_prontos,
                'pedidos_pendentes': pedidos_pendentes
            }
        })
        
    except Exception as e:
        logger.error(f"Erro ao buscar resultados: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@carteira_bp.route('/api/ruptura/analisar-todos-async', methods=['POST'])
def analisar_todos_pedidos_async():
    """
    Enfileira TODOS os pedidos da carteira para an치lise
    """
    try:
        from app import db
        from app.carteira.models import CarteiraPrincipal
        
        data = request.get_json() or {}
        filtros = data.get('filtros', {})
        
        # Buscar todos os pedidos ativos
        query = db.session.query(
            CarteiraPrincipal.num_pedido
        ).filter(
            CarteiraPrincipal.ativo == True
        ).distinct()
        
        # Aplicar filtros opcionais
        if filtros.get('vendedor'):
            query = query.filter(CarteiraPrincipal.vendedor == filtros['vendedor'])
        if filtros.get('equipe_vendas'):
            query = query.filter(CarteiraPrincipal.equipe_vendas == filtros['equipe_vendas'])
        if filtros.get('estado'):
            query = query.filter(CarteiraPrincipal.estado == filtros['estado'])
        
        pedidos = query.all()
        pedidos_ids = [p.num_pedido for p in pedidos]
        
        if not pedidos_ids:
            return jsonify({
                'success': False,
                'message': 'Nenhum pedido encontrado'
            }), 404
        
        logger.info(f"游늵 Encontrados {len(pedidos_ids)} pedidos para an치lise")
        
        # Limpar cache antigo
        for pedido_id in pedidos_ids:
            redis_conn.delete(f"{REDIS_PREFIX}{pedido_id}")
        
        # Enfileirar em lotes de 50 pedidos para otimizar
        tamanho_lote = 50
        lotes = [pedidos_ids[i:i + tamanho_lote] 
                 for i in range(0, len(pedidos_ids), tamanho_lote)]
        
        jobs_enfileirados = 0
        
        for i, lote in enumerate(lotes):
            job = queue_atacadao.enqueue(
                'app.portal.workers.ruptura_jobs.processar_lote_ruptura',
                lote,
                {'salvar_redis': True, 'redis_prefix': REDIS_PREFIX, 'redis_ttl': REDIS_TTL},
                job_timeout='10m'
            )
            jobs_enfileirados += 1
            logger.info(f"Lote {i+1}/{len(lotes)} enfileirado - Job ID: {job.id}")
        
        return jsonify({
            'success': True,
            'message': f'{len(pedidos_ids)} pedidos enfileirados em {jobs_enfileirados} lotes',
            'total_pedidos': len(pedidos_ids),
            'lotes_enfileirados': jobs_enfileirados
        })
        
    except Exception as e:
        logger.error(f"Erro ao analisar todos os pedidos: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500