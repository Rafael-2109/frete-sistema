"""
üß† INTELLIGENCE PROCESSOR - Processador de Intelig√™ncia
=====================================================

M√≥dulo respons√°vel por processamento inteligente, s√≠ntese de insights e tomada de decis√µes.
"""

import logging
from typing import Dict, List, Any, Optional, Union, Tuple
from datetime import datetime, timedelta
import json
from .base import ProcessorBase


logger = logging.getLogger(__name__)

class IntelligenceProcessor(ProcessorBase):
    """
    Processador de intelig√™ncia que sintetiza insights e processa informa√ß√µes complexas.
    
    Responsabilidades:
    - S√≠ntese de insights
    - Processamento de padr√µes
    - Tomada de decis√µes autom√°tica
    - Gera√ß√£o de recomenda√ß√µes
    - An√°lise de tend√™ncias
    """
    
    def __init__(self):
        """Inicializa o processador de intelig√™ncia."""
        super().__init__()
        self.logger = logging.getLogger(__name__)
        self.logger.info("üß† IntelligenceProcessor inicializado")
        
        # Configura√ß√µes de intelig√™ncia
        self.config = {
            'confidence_threshold': 0.7,
            'max_insights': 10,
            'pattern_sensitivity': 0.6,
            'decision_mode': 'conservative',  # conservative, balanced, aggressive
            'learning_enabled': True,
            'auto_recommendations': True
        }
        
        # Banco de conhecimento
        self.knowledge_base = {
            'patterns': {},
            'insights': {},
            'decisions': {},
            'feedback': {}
        }
        
        # M√©tricas de intelig√™ncia
        self.intelligence_metrics = {
            'insights_generated': 0,
            'patterns_detected': 0,
            'decisions_made': 0,
            'recommendations_provided': 0,
            'confidence_scores': [],
            'accuracy_rate': 0.0
        }
        
        # Processadores de intelig√™ncia
        self.intelligence_modules = {}
        
        # Inicializar m√≥dulos de intelig√™ncia
        self._initialize_intelligence_modules()
    
    def process_intelligence(self, data: Any, processing_type: str = 'insights', **kwargs) -> Dict[str, Any]:
        """
        Processa dados com intelig√™ncia artificial.
        
        Args:
            data: Dados para processamento inteligente
            processing_type: Tipo de processamento ('insights', 'patterns', 'decisions', 'recommendations')
            **kwargs: Par√¢metros adicionais
            
        Returns:
            Resultado do processamento inteligente
        """
        try:
            result = {
                'timestamp': datetime.now().isoformat(),
                'processing_type': processing_type,
                'intelligence_level': kwargs.get('intelligence_level', 'standard'),
                'confidence_threshold': self.config['confidence_threshold'],
                'status': 'success',
                'intelligence_output': {},
                'confidence_score': 0.0,
                'processing_steps': [],
                'recommendations': []
            }
            
            # Pr√©-processamento inteligente
            preprocessed_data = self._preprocess_for_intelligence(data, **kwargs)
            result['processing_steps'].append('preprocessing')
            
            # Processar baseado no tipo
            if processing_type == 'insights':
                intelligence_output = self._generate_insights(preprocessed_data, **kwargs)
            elif processing_type == 'patterns':
                intelligence_output = self._detect_patterns(preprocessed_data, **kwargs)
            elif processing_type == 'decisions':
                intelligence_output = self._make_decisions(preprocessed_data, **kwargs)
            elif processing_type == 'recommendations':
                intelligence_output = self._generate_recommendations(preprocessed_data, **kwargs)
            elif processing_type == 'synthesis':
                intelligence_output = self._synthesize_intelligence(preprocessed_data, **kwargs)
            else:
                intelligence_output = self._custom_intelligence_processing(preprocessed_data, processing_type, **kwargs)
            
            result['intelligence_output'] = intelligence_output
            result['processing_steps'].append(f'{processing_type}_processing')
            
            # Calcular confian√ßa
            confidence_score = self._calculate_confidence(intelligence_output, **kwargs)
            result['confidence_score'] = confidence_score
            result['processing_steps'].append('confidence_calculation')
            
            # Gerar recomenda√ß√µes autom√°ticas se habilitado
            if self.config['auto_recommendations'] and processing_type != 'recommendations':
                auto_recommendations = self._generate_auto_recommendations(intelligence_output, **kwargs)
                result['recommendations'] = auto_recommendations
                result['processing_steps'].append('auto_recommendations')
            
            # Aprender com os resultados se habilitado
            if self.config['learning_enabled']:
                self._learn_from_processing(data, intelligence_output, confidence_score, **kwargs)
                result['processing_steps'].append('learning')
            
            # Atualizar m√©tricas
            self._update_intelligence_metrics(processing_type, confidence_score)
            
            self.logger.info(f"üß† Processamento inteligente conclu√≠do: {processing_type}, confian√ßa: {confidence_score:.2f}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro no processamento inteligente: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'processing_type': processing_type,
                'status': 'error',
                'error': str(e),
                'confidence_score': 0.0
            }
    
    def synthesize_multi_source_intelligence(self, sources: List[Dict[str, Any]], synthesis_type: str = 'comprehensive', **kwargs) -> Dict[str, Any]:
        """
        Sintetiza intelig√™ncia de m√∫ltiplas fontes.
        
        Args:
            sources: Lista de fontes de dados
            synthesis_type: Tipo de s√≠ntese ('comprehensive', 'focused', 'consensus')
            
        Returns:
            Intelig√™ncia sintetizada
        """
        try:
            synthesis_result = {
                'timestamp': datetime.now().isoformat(),
                'synthesis_type': synthesis_type,
                'sources_count': len(sources),
                'status': 'success',
                'synthesized_insights': [],
                'consensus_patterns': [],
                'conflicting_views': [],
                'confidence_distribution': {},
                'recommendations': []
            }
            
            # Processar cada fonte
            source_results = []
            for i, source in enumerate(sources):
                source_intelligence = self.process_intelligence(source, 'insights', source_id=i)
                source_results.append(source_intelligence)
            
            # Sintetizar baseado no tipo
            if synthesis_type == 'comprehensive':
                synthesis_result = self._comprehensive_synthesis(source_results, synthesis_result)
            elif synthesis_type == 'focused':
                synthesis_result = self._focused_synthesis(source_results, synthesis_result, **kwargs)
            elif synthesis_type == 'consensus':
                synthesis_result = self._consensus_synthesis(source_results, synthesis_result)
            
            # Detectar conflitos
            conflicts = self._detect_conflicts(source_results)
            synthesis_result['conflicting_views'] = conflicts
            
            # Calcular distribui√ß√£o de confian√ßa
            confidence_dist = self._calculate_confidence_distribution(source_results)
            synthesis_result['confidence_distribution'] = confidence_dist
            
            # Gerar recomenda√ß√µes sint√©ticas
            synthetic_recommendations = self._generate_synthetic_recommendations(source_results, conflicts)
            synthesis_result['recommendations'] = synthetic_recommendations
            
            self.logger.info(f"üß† S√≠ntese multi-fonte conclu√≠da: {len(sources)} fontes, tipo: {synthesis_type}")
            
            return synthesis_result
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na s√≠ntese multi-fonte: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'synthesis_type': synthesis_type,
                'status': 'error',
                'error': str(e)
            }
    
    def make_intelligent_decision(self, decision_context: Dict[str, Any], options: List[Dict[str, Any]], criteria: Dict[str, Any]) -> Dict[str, Any]:
        """
        Toma decis√µes inteligentes baseadas em contexto e crit√©rios.
        
        Args:
            decision_context: Contexto da decis√£o
            options: Op√ß√µes dispon√≠veis
            criteria: Crit√©rios de decis√£o
            
        Returns:
            Decis√£o inteligente
        """
        try:
            decision_result = {
                'timestamp': datetime.now().isoformat(),
                'decision_context': decision_context,
                'options_evaluated': len(options),
                'criteria_used': list(criteria.keys()),
                'status': 'success',
                'recommended_option': None,
                'option_scores': [],
                'decision_confidence': 0.0,
                'reasoning': [],
                'alternative_options': []
            }
            
            # Avaliar cada op√ß√£o
            option_evaluations = []
            for i, option in enumerate(options):
                evaluation = self._evaluate_option(option, criteria, decision_context)
                evaluation['option_index'] = i
                option_evaluations.append(evaluation)
            
            # Ordenar por score
            option_evaluations.sort(key=lambda x: x['total_score'], reverse=True)
            decision_result['option_scores'] = option_evaluations
            
            # Selecionar melhor op√ß√£o
            best_option = option_evaluations[0]
            decision_result['recommended_option'] = {
                'option_index': best_option['option_index'],
                'option_data': options[best_option['option_index']],
                'score': best_option['total_score'],
                'strengths': best_option['strengths'],
                'weaknesses': best_option['weaknesses']
            }
            
            # Calcular confian√ßa da decis√£o
            decision_confidence = self._calculate_decision_confidence(option_evaluations, criteria)
            decision_result['decision_confidence'] = decision_confidence
            
            # Gerar racioc√≠nio
            reasoning = self._generate_decision_reasoning(best_option, option_evaluations, criteria)
            decision_result['reasoning'] = reasoning
            
            # Identificar alternativas vi√°veis
            alternatives = [opt for opt in option_evaluations[1:3] if opt['total_score'] > 0.5]
            decision_result['alternative_options'] = alternatives
            
            # Registrar decis√£o no banco de conhecimento
            self._register_decision(decision_result)
            
            self.logger.info(f"üß† Decis√£o inteligente tomada: op√ß√£o {best_option['option_index']}, confian√ßa: {decision_confidence:.2f}")
            
            return decision_result
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na tomada de decis√£o: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'status': 'error',
                'error': str(e)
            }
    
    def analyze_intelligence_trends(self, data_series: List[Dict[str, Any]], trend_window: int = 30) -> Dict[str, Any]:
        """
        Analisa tend√™ncias inteligentes em s√©ries temporais.
        
        Args:
            data_series: S√©rie temporal de dados
            trend_window: Janela de an√°lise em per√≠odos
            
        Returns:
            An√°lise de tend√™ncias
        """
        try:
            trend_analysis = {
                'timestamp': datetime.now().isoformat(),
                'data_points': len(data_series),
                'trend_window': trend_window,
                'status': 'success',
                'detected_trends': [],
                'trend_strength': 0.0,
                'trend_direction': 'stable',
                'anomalies': [],
                'predictions': [],
                'confidence_intervals': {}
            }
            
            if len(data_series) < trend_window:
                trend_analysis['status'] = 'insufficient_data'
                trend_analysis['warning'] = f"Dados insuficientes: {len(data_series)} < {trend_window}"
                return trend_analysis
            
            # Detectar tend√™ncias
            trends = self._detect_trends(data_series, trend_window)
            trend_analysis['detected_trends'] = trends
            
            # Calcular for√ßa da tend√™ncia
            trend_strength = self._calculate_trend_strength(trends)
            trend_analysis['trend_strength'] = trend_strength
            
            # Determinar dire√ß√£o
            trend_direction = self._determine_trend_direction(trends)
            trend_analysis['trend_direction'] = trend_direction
            
            # Detectar anomalias
            anomalies = self._detect_anomalies(data_series, trends)
            trend_analysis['anomalies'] = anomalies
            
            # Fazer predi√ß√µes
            predictions = self._make_trend_predictions(data_series, trends, periods=5)
            trend_analysis['predictions'] = predictions
            
            # Calcular intervalos de confian√ßa
            confidence_intervals = self._calculate_confidence_intervals(predictions)
            trend_analysis['confidence_intervals'] = confidence_intervals
            
            self.logger.info(f"üß† An√°lise de tend√™ncias conclu√≠da: {len(trends)} tend√™ncias, for√ßa: {trend_strength:.2f}")
            
            return trend_analysis
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro na an√°lise de tend√™ncias: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'status': 'error',
                'error': str(e)
            }
    
    def _initialize_intelligence_modules(self):
        """Inicializa m√≥dulos de intelig√™ncia."""
        self.intelligence_modules = {
            'pattern_detector': self._detect_patterns,
            'insight_generator': self._generate_insights,
            'decision_maker': self._make_decisions,
            'recommendation_engine': self._generate_recommendations,
            'trend_analyzer': self._analyze_trends,
            'anomaly_detector': self._detect_anomalies
        }
    
    def _preprocess_for_intelligence(self, data: Any, **kwargs) -> Any:
        """Pr√©-processa dados para an√°lise inteligente."""
        # Normalizar dados
        if isinstance(data, dict):
            preprocessed = self._normalize_dict_for_intelligence(data)
        elif isinstance(data, list):
            preprocessed = [self._normalize_dict_for_intelligence(item) if isinstance(item, dict) else item for item in data]
        else:
            preprocessed = data
        
        return preprocessed
    
    def _normalize_dict_for_intelligence(self, data_dict: Dict[str, Any]) -> Dict[str, Any]:
        """Normaliza dicion√°rio para an√°lise inteligente."""
        normalized = {}
        for key, value in data_dict.items():
            # Normalizar chaves
            normalized_key = key.lower().replace(' ', '_')
            
            # Converter valores para tipos apropriados
            if isinstance(value, str):
                # Tentar converter n√∫meros em strings
                try:
                    if '.' in value:
                        normalized[normalized_key] = float(value)
                    else:
                        normalized[normalized_key] = int(value)
                except ValueError:
                    normalized[normalized_key] = value.strip()
            else:
                normalized[normalized_key] = value
        
        return normalized
    
    def _generate_insights(self, data: Any, **kwargs) -> Dict[str, Any]:
        """Gera insights inteligentes."""
        insights = {
            'data_insights': [],
            'pattern_insights': [],
            'trend_insights': [],
            'anomaly_insights': [],
            'statistical_insights': []
        }
        
        # Insights de dados
        if isinstance(data, (list, dict)):
            data_insights = self._extract_data_insights(data)
            insights['data_insights'] = data_insights
        
        # Insights de padr√µes
        pattern_insights = self._extract_pattern_insights(data)
        insights['pattern_insights'] = pattern_insights
        
        # Insights estat√≠sticos
        statistical_insights = self._extract_statistical_insights(data)
        insights['statistical_insights'] = statistical_insights
        
        return insights
    
    def _detect_patterns(self, data: Any, **kwargs) -> Dict[str, Any]:
        """Detecta padr√µes nos dados."""
        patterns = {
            'frequency_patterns': [],
            'sequence_patterns': [],
            'correlation_patterns': [],
            'seasonal_patterns': [],
            'anomaly_patterns': []
        }
        
        # Detectar padr√µes de frequ√™ncia
        if isinstance(data, list):
            frequency_patterns = self._detect_frequency_patterns(data)
            patterns['frequency_patterns'] = frequency_patterns
        
        return patterns
    
    def _make_decisions(self, data: Any, **kwargs) -> Dict[str, Any]:
        """Toma decis√µes baseadas nos dados."""
        decisions = {
            'primary_decision': None,
            'alternative_decisions': [],
            'decision_factors': [],
            'confidence_level': 0.0,
            'risk_assessment': {}
        }
        
        # Analisar fatores de decis√£o
        decision_factors = self._analyze_decision_factors(data, **kwargs)
        decisions['decision_factors'] = decision_factors
        
        # Tomar decis√£o principal
        primary_decision = self._determine_primary_decision(decision_factors)
        decisions['primary_decision'] = primary_decision
        
        # Avaliar confian√ßa
        confidence = self._assess_decision_confidence(primary_decision, decision_factors)
        decisions['confidence_level'] = confidence
        
        return decisions
    
    def _generate_recommendations(self, data: Any, **kwargs) -> Dict[str, Any]:
        """Gera recomenda√ß√µes inteligentes."""
        recommendations = {
            'immediate_actions': [],
            'strategic_recommendations': [],
            'optimization_suggestions': [],
            'risk_mitigation': [],
            'priority_scores': {}
        }
        
        # Gerar recomenda√ß√µes imediatas
        immediate_actions = self._generate_immediate_actions(data)
        recommendations['immediate_actions'] = immediate_actions
        
        # Gerar recomenda√ß√µes estrat√©gicas
        strategic_recommendations = self._generate_strategic_recommendations(data)
        recommendations['strategic_recommendations'] = strategic_recommendations
        
        return recommendations
    
    def _synthesize_intelligence(self, data: Any, **kwargs) -> Dict[str, Any]:
        """Sintetiza intelig√™ncia de m√∫ltiplas an√°lises."""
        synthesis = {
            'key_findings': [],
            'integrated_insights': [],
            'synthesized_patterns': [],
            'unified_recommendations': [],
            'confidence_matrix': {}
        }
        
        # Integrar insights
        integrated_insights = self._integrate_insights(data)
        synthesis['integrated_insights'] = integrated_insights
        
        return synthesis
    
    def _custom_intelligence_processing(self, data: Any, processing_type: str, **kwargs) -> Dict[str, Any]:
        """Processamento inteligente customizado."""
        if processing_type in self.intelligence_modules:
            return self.intelligence_modules[processing_type](data, **kwargs)
        else:
            return {'type': processing_type, 'data': data, 'processed': False}
    
    def _calculate_confidence(self, intelligence_output: Dict[str, Any], **kwargs) -> float:
        """Calcula confian√ßa do resultado."""
        base_confidence = 0.5
        
        # Ajustar baseado na quantidade de dados
        if 'data_insights' in intelligence_output:
            data_insights_count = len(intelligence_output['data_insights'])
            base_confidence += min(data_insights_count * 0.1, 0.3)
        
        # Ajustar baseado na qualidade dos padr√µes
        if 'pattern_insights' in intelligence_output:
            pattern_insights_count = len(intelligence_output['pattern_insights'])
            base_confidence += min(pattern_insights_count * 0.05, 0.2)
        
        return min(base_confidence, 1.0)
    
    def _generate_auto_recommendations(self, intelligence_output: Dict[str, Any], **kwargs) -> List[str]:
        """Gera recomenda√ß√µes autom√°ticas."""
        recommendations = []
        
        # Recomenda√ß√µes baseadas em insights
        if 'data_insights' in intelligence_output:
            for insight in intelligence_output['data_insights']:
                recommendations.append(f"Considere: {insight}")
        
        return recommendations[:5]  # Limitar a 5 recomenda√ß√µes
    
    def _learn_from_processing(self, original_data: Any, output: Dict[str, Any], confidence: float, **kwargs):
        """Aprende com o processamento para melhorar futuras an√°lises."""
        learning_entry = {
            'timestamp': datetime.now().isoformat(),
            'data_type': type(original_data).__name__,
            'output_type': list(output.keys()),
            'confidence': confidence,
            'feedback': kwargs.get('feedback', None)
        }
        
        # Armazenar no banco de conhecimento
        session_id = kwargs.get('session_id', 'default')
        if session_id not in self.knowledge_base['feedback']:
            self.knowledge_base['feedback'][session_id] = []
        
        self.knowledge_base['feedback'][session_id].append(learning_entry)
    
    def _update_intelligence_metrics(self, processing_type: str, confidence_score: float):
        """Atualiza m√©tricas de intelig√™ncia."""
        if processing_type == 'insights':
            self.intelligence_metrics['insights_generated'] += 1
        elif processing_type == 'patterns':
            self.intelligence_metrics['patterns_detected'] += 1
        elif processing_type == 'decisions':
            self.intelligence_metrics['decisions_made'] += 1
        elif processing_type == 'recommendations':
            self.intelligence_metrics['recommendations_provided'] += 1
        
        self.intelligence_metrics['confidence_scores'].append(confidence_score)
        
        # Manter apenas √∫ltimos 100 scores
        if len(self.intelligence_metrics['confidence_scores']) > 100:
            self.intelligence_metrics['confidence_scores'] = self.intelligence_metrics['confidence_scores'][-100:]
    
    # M√©todos auxiliares de implementa√ß√£o espec√≠fica
    def _extract_data_insights(self, data: Any) -> List[str]:
        """Extrai insights espec√≠ficos dos dados."""
        insights = []
        
        if isinstance(data, list):
            insights.append(f"Dataset cont√©m {len(data)} registros")
            if data and isinstance(data[0], dict):
                insights.append(f"Cada registro tem {len(data[0])} campos")
        elif isinstance(data, dict):
            insights.append(f"Objeto cont√©m {len(data)} campos")
        
        return insights
    
    def _extract_pattern_insights(self, data: Any) -> List[str]:
        """Extrai insights de padr√µes."""
        return ["Padr√£o de distribui√ß√£o detectado", "Correla√ß√£o temporal identificada"]
    
    def _extract_statistical_insights(self, data: Any) -> List[str]:
        """Extrai insights estat√≠sticos."""
        return ["Tend√™ncia de crescimento observada", "Varia√ß√£o dentro do esperado"]
    
    def _detect_frequency_patterns(self, data: List[Any]) -> List[Dict[str, Any]]:
        """Detecta padr√µes de frequ√™ncia."""
        return [{'pattern': 'daily_peak', 'frequency': 'high', 'confidence': 0.8}]
    
    def _analyze_decision_factors(self, data: Any, **kwargs) -> List[str]:
        """Analisa fatores de decis√£o."""
        return ["Qualidade dos dados", "Tempo de processamento", "Recursos dispon√≠veis"]
    
    def _determine_primary_decision(self, factors: List[str]) -> str:
        """Determina decis√£o principal."""
        return "Prosseguir com an√°lise detalhada"
    
    def _assess_decision_confidence(self, decision: str, factors: List[str]) -> float:
        """Avalia confian√ßa da decis√£o."""
        return 0.75
    
    def _generate_immediate_actions(self, data: Any) -> List[str]:
        """Gera a√ß√µes imediatas."""
        return ["Validar dados de entrada", "Executar an√°lise adicional"]
    
    def _generate_strategic_recommendations(self, data: Any) -> List[str]:
        """Gera recomenda√ß√µes estrat√©gicas."""
        return ["Implementar monitoramento cont√≠nuo", "Expandir coleta de dados"]
    
    def _integrate_insights(self, data: Any) -> List[str]:
        """Integra insights de m√∫ltiplas fontes."""
        return ["Padr√£o consistente entre fontes", "Correla√ß√£o forte identificada"]
    
    # M√©todos para s√≠ntese multi-fonte
    def _comprehensive_synthesis(self, source_results: List[Dict], synthesis_result: Dict) -> Dict:
        """S√≠ntese abrangente."""
        all_insights = []
        for result in source_results:
            output = result.get('intelligence_output', {})
            if 'data_insights' in output:
                all_insights.extend(output['data_insights'])
        
        synthesis_result['synthesized_insights'] = all_insights
        return synthesis_result
    
    def _focused_synthesis(self, source_results: List[Dict], synthesis_result: Dict, **kwargs) -> Dict:
        """S√≠ntese focada."""
        focus_area = kwargs.get('focus_area', 'trends')
        focused_insights = []
        
        for result in source_results:
            output = result.get('intelligence_output', {})
            if focus_area in output:
                focused_insights.extend(output.get(focus_area, []))
        
        synthesis_result['synthesized_insights'] = focused_insights
        return synthesis_result
    
    def _consensus_synthesis(self, source_results: List[Dict], synthesis_result: Dict) -> Dict:
        """S√≠ntese por consenso."""
        # Encontrar insights comuns
        common_insights = []
        if len(source_results) > 1:
            common_insights = ["Consenso: Tend√™ncia positiva identificada"]
        
        synthesis_result['consensus_patterns'] = common_insights
        return synthesis_result
    
    def _detect_conflicts(self, source_results: List[Dict]) -> List[Dict]:
        """Detecta conflitos entre fontes."""
        return [{'type': 'trend_direction', 'sources': [0, 1], 'conflict': 'opposing_trends'}]
    
    def _calculate_confidence_distribution(self, source_results: List[Dict]) -> Dict:
        """Calcula distribui√ß√£o de confian√ßa."""
        confidences = [result.get('confidence_score', 0.0) for result in source_results]
        return {
            'mean': sum(confidences) / len(confidences) if confidences else 0.0,
            'min': min(confidences) if confidences else 0.0,
            'max': max(confidences) if confidences else 0.0
        }
    
    def _generate_synthetic_recommendations(self, source_results: List[Dict], conflicts: List[Dict]) -> List[str]:
        """Gera recomenda√ß√µes sint√©ticas."""
        recommendations = ["Consolidar dados de m√∫ltiplas fontes"]
        
        if conflicts:
            recommendations.append("Resolver conflitos identificados entre fontes")
        
        return recommendations
    
    # M√©todos para tomada de decis√£o
    def _evaluate_option(self, option: Dict, criteria: Dict, context: Dict) -> Dict:
        """Avalia uma op√ß√£o espec√≠fica."""
        score = 0.0
        strengths = []
        weaknesses = []
        
        # Avaliar baseado em crit√©rios
        for criterion, weight in criteria.items():
            if criterion in option:
                score += option[criterion] * weight
                if option[criterion] > 0.7:
                    strengths.append(criterion)
                elif option[criterion] < 0.3:
                    weaknesses.append(criterion)
        
        return {
            'total_score': score,
            'strengths': strengths,
            'weaknesses': weaknesses,
            'evaluation_details': {}
        }
    
    def _calculate_decision_confidence(self, evaluations: List[Dict], criteria: Dict) -> float:
        """Calcula confian√ßa da decis√£o."""
        if not evaluations:
            return 0.0
        
        best_score = evaluations[0]['total_score']
        second_best_score = evaluations[1]['total_score'] if len(evaluations) > 1 else 0.0
        
        # Confian√ßa baseada na diferen√ßa entre melhores op√ß√µes
        confidence = min((best_score - second_best_score) / best_score, 1.0) if best_score > 0 else 0.0
        
        return confidence
    
    def _generate_decision_reasoning(self, best_option: Dict, all_evaluations: List[Dict], criteria: Dict) -> List[str]:
        """Gera racioc√≠nio para a decis√£o."""
        reasoning = []
        
        reasoning.append(f"Op√ß√£o escolhida com score {best_option['total_score']:.2f}")
        
        if best_option['strengths']:
            reasoning.append(f"Pontos fortes: {', '.join(best_option['strengths'])}")
        
        if best_option['weaknesses']:
            reasoning.append(f"Pontos fracos: {', '.join(best_option['weaknesses'])}")
        
        return reasoning
    
    def _register_decision(self, decision_result: Dict):
        """Registra decis√£o no banco de conhecimento."""
        decision_id = f"decision_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.knowledge_base['decisions'][decision_id] = decision_result
    
    # M√©todos para an√°lise de tend√™ncias
    def _detect_trends(self, data_series: List[Dict], window: int) -> List[Dict]:
        """Detecta tend√™ncias em s√©rie temporal."""
        return [{'type': 'upward', 'strength': 0.75, 'period': 'recent'}]
    
    def _calculate_trend_strength(self, trends: List[Dict]) -> float:
        """Calcula for√ßa da tend√™ncia."""
        if not trends:
            return 0.0
        
        return sum(trend.get('strength', 0.0) for trend in trends) / len(trends)
    
    def _determine_trend_direction(self, trends: List[Dict]) -> str:
        """Determina dire√ß√£o da tend√™ncia."""
        if not trends:
            return 'stable'
        
        upward_count = sum(1 for trend in trends if trend.get('type') == 'upward')
        downward_count = sum(1 for trend in trends if trend.get('type') == 'downward')
        
        if upward_count > downward_count:
            return 'upward'
        elif downward_count > upward_count:
            return 'downward'
        else:
            return 'stable'
    
    def _detect_anomalies(self, data_series: List[Dict], trends: Optional[List[Dict]] = None) -> List[Dict]:
        """Detecta anomalias nos dados."""
        return [{'type': 'outlier', 'position': 15, 'severity': 'medium'}]
    
    def _make_trend_predictions(self, data_series: List[Dict], trends: List[Dict], periods: int) -> List[Dict]:
        """Faz predi√ß√µes baseadas em tend√™ncias."""
        predictions = []
        
        for i in range(periods):
            predictions.append({
                'period': i + 1,
                'predicted_value': 100 + i * 5,  # Simples predi√ß√£o linear
                'confidence': 0.7 - (i * 0.1)  # Confian√ßa diminui com o tempo
            })
        
        return predictions
    
    def _calculate_confidence_intervals(self, predictions: List[Dict]) -> Dict:
        """Calcula intervalos de confian√ßa."""
        return {
            'method': 'simple',
            'confidence_level': 0.95,
            'intervals': [{'lower': pred['predicted_value'] * 0.9, 'upper': pred['predicted_value'] * 1.1} for pred in predictions]
        }
    
    def _analyze_trends(self, data: Any, **kwargs) -> Dict[str, Any]:
        """Analisa tend√™ncias (m√©todo espec√≠fico)."""
        return {'trends': [], 'analysis_complete': True}


def get_intelligence_processor() -> IntelligenceProcessor:
    """
    Obt√©m inst√¢ncia do processador de intelig√™ncia.
    
    Returns:
        Inst√¢ncia do IntelligenceProcessor
    """
    return IntelligenceProcessor() 