#!/usr/bin/env python3
"""
DiagnÃ³stico de Respostas GenÃ©ricas - Claude AI Novo
Identifica porque o sistema estÃ¡ dando respostas padrÃ£o em vez de dados reais
"""

import os
import sys
from pathlib import Path
import json
import ast
from typing import Dict, List, Any

class GenericResponseDiagnostic:
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.issues = []
        self.findings = []
        
    def check_response_processor(self):
        """Verifica o ResponseProcessor que gera as respostas"""
        print("\nðŸ” Analisando ResponseProcessor...")
        print("=" * 60)
        
        response_processor_path = self.base_dir / 'utils' / 'base_classes.py'
        
        if response_processor_path.exists():
            with open(response_processor_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Verificar se estÃ¡ usando dados reais
            if 'dados reais' in content.lower() or 'real_data' in content.lower():
                print("âœ… ResponseProcessor menciona dados reais")
                self.findings.append("ResponseProcessor tem referÃªncia a dados reais")
            else:
                print("âš ï¸  ResponseProcessor nÃ£o menciona dados reais explicitamente")
                
            # Verificar se estÃ¡ chamando providers
            if 'provider' in content.lower():
                print("âœ… ResponseProcessor usa providers")
                self.findings.append("ResponseProcessor integra com providers")
            else:
                print("âŒ ResponseProcessor nÃ£o parece usar providers")
                self.issues.append({
                    'type': 'missing_provider_integration',
                    'file': 'utils/base_classes.py',
                    'severity': 'high'
                })
                
            # Verificar templates de resposta
            if 'template' in content or 'Como assistente' in content:
                print("âš ï¸  ResponseProcessor pode estar usando templates fixos")
                self.issues.append({
                    'type': 'fixed_templates',
                    'file': 'utils/base_classes.py',
                    'severity': 'medium'
                })
                
    def check_data_flow(self):
        """Verifica o fluxo de dados do sistema"""
        print("\n\nðŸ”„ Analisando Fluxo de Dados...")
        print("=" * 60)
        
        # Verificar DataProvider
        data_provider_path = self.base_dir / 'providers' / 'data_provider.py'
        
        if data_provider_path.exists():
            with open(data_provider_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Verificar se estÃ¡ acessando banco
            if 'db.session' in content or 'query' in content:
                print("âœ… DataProvider acessa banco de dados")
                self.findings.append("DataProvider tem queries ao banco")
            else:
                print("âŒ DataProvider nÃ£o parece acessar banco")
                self.issues.append({
                    'type': 'no_database_access',
                    'file': 'providers/data_provider.py',
                    'severity': 'critical'
                })
                
            # Verificar mÃ©todos especÃ­ficos
            if 'obter_entregas' in content or 'get_deliveries' in content:
                print("âœ… DataProvider tem mÃ©todo para entregas")
            else:
                print("âš ï¸  DataProvider nÃ£o tem mÃ©todo especÃ­fico para entregas")
                
    def check_orchestrator_flow(self):
        """Verifica como os orchestrators processam as queries"""
        print("\n\nðŸŽ­ Analisando Orchestrators...")
        print("=" * 60)
        
        orchestrator_path = self.base_dir / 'orchestrators' / 'orchestrator_manager.py'
        
        if orchestrator_path.exists():
            with open(orchestrator_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Verificar se usa workflow de dados reais
            if 'data_provider' in content.lower() or 'real_data' in content.lower():
                print("âœ… Orchestrator integra com dados reais")
            else:
                print("âŒ Orchestrator nÃ£o menciona integraÃ§Ã£o com dados")
                self.issues.append({
                    'type': 'orchestrator_no_data_integration',
                    'file': 'orchestrators/orchestrator_manager.py',
                    'severity': 'high'
                })
                
    def check_analyzer_integration(self):
        """Verifica se analyzers estÃ£o processando corretamente"""
        print("\n\nðŸ§  Analisando Analyzers...")
        print("=" * 60)
        
        analyzer_path = self.base_dir / 'analyzers' / 'intention_analyzer.py'
        
        if analyzer_path.exists():
            with open(analyzer_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Verificar detecÃ§Ã£o de intenÃ§Ã£o
            if 'entregas' in content.lower() or 'delivery' in content.lower():
                print("âœ… Analyzer reconhece queries de entregas")
            else:
                print("âš ï¸  Analyzer pode nÃ£o reconhecer queries de entregas")
                
    def check_config_loading(self):
        """Verifica se configuraÃ§Ãµes estÃ£o sendo carregadas"""
        print("\n\nâš™ï¸ Verificando Carregamento de ConfiguraÃ§Ãµes...")
        print("=" * 60)
        
        # Verificar se semantic_mapping.json estÃ¡ sendo usado
        semantic_used = False
        
        for root, dirs, files in os.walk(self.base_dir):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            
            for file in files:
                if file.endswith('.py'):
                    file_path = Path(root) / file
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        if 'semantic_mapping.json' in content:
                            semantic_used = True
                            print(f"âœ… semantic_mapping.json usado em: {file_path.relative_to(self.base_dir)}")
                            break
                    except:
                        pass
                        
        if not semantic_used:
            print("âŒ semantic_mapping.json nÃ£o estÃ¡ sendo carregado!")
            self.issues.append({
                'type': 'config_not_loaded',
                'file': 'config/semantic_mapping.json',
                'severity': 'high'
            })
            
    def analyze_response_generation(self):
        """Analisa como as respostas sÃ£o geradas"""
        print("\n\nðŸ“ Analisando GeraÃ§Ã£o de Respostas...")
        print("=" * 60)
        
        # Buscar onde as respostas genÃ©ricas sÃ£o criadas
        generic_patterns = [
            "Como assistente",
            "preciso informar",
            "nÃ£o tenho acesso",
            "dados especÃ­ficos",
            "seria necessÃ¡rio"
        ]
        
        files_with_generic = []
        
        for root, dirs, files in os.walk(self.base_dir):
            dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__pycache__']
            
            for file in files:
                if file.endswith('.py'):
                    file_path = Path(root) / file
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        for pattern in generic_patterns:
                            if pattern in content:
                                files_with_generic.append({
                                    'file': str(file_path.relative_to(self.base_dir)),
                                    'pattern': pattern
                                })
                                break
                    except:
                        pass
                        
        if files_with_generic:
            print(f"âš ï¸  Encontrados {len(files_with_generic)} arquivos com padrÃµes genÃ©ricos:")
            for item in files_with_generic[:5]:  # Mostrar apenas os 5 primeiros
                print(f"   - {item['file']}: '{item['pattern']}'")
                
    def generate_report(self):
        """Gera relatÃ³rio de diagnÃ³stico"""
        report = {
            'summary': {
                'total_issues': len(self.issues),
                'critical_issues': len([i for i in self.issues if i['severity'] == 'critical']),
                'findings': len(self.findings)
            },
            'issues': self.issues,
            'findings': self.findings,
            'recommendations': []
        }
        
        # Gerar recomendaÃ§Ãµes baseadas nos issues
        if any(i['type'] == 'no_database_access' for i in self.issues):
            report['recommendations'].append({
                'priority': 'HIGH',
                'action': 'Verificar integraÃ§Ã£o do DataProvider com banco de dados',
                'description': 'O DataProvider nÃ£o estÃ¡ acessando o banco para buscar dados reais'
            })
            
        if any(i['type'] == 'orchestrator_no_data_integration' for i in self.issues):
            report['recommendations'].append({
                'priority': 'HIGH',
                'action': 'Integrar Orchestrator com DataProvider',
                'description': 'O Orchestrator precisa chamar o DataProvider para obter dados reais'
            })
            
        if any(i['type'] == 'config_not_loaded' for i in self.issues):
            report['recommendations'].append({
                'priority': 'MEDIUM',
                'action': 'Carregar configuraÃ§Ãµes semÃ¢nticas',
                'description': 'O arquivo semantic_mapping.json nÃ£o estÃ¡ sendo utilizado'
            })
            
        # Salvar relatÃ³rio
        with open(self.base_dir / 'diagnostico_resposta_generica.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
            
        # Criar relatÃ³rio Markdown
        self._create_markdown_report(report)
        
        return report
        
    def _create_markdown_report(self, report):
        """Cria relatÃ³rio em Markdown"""
        md = ["# ðŸ” DIAGNÃ“STICO: Respostas GenÃ©ricas\n"]
        md.append(f"**Data**: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # Resumo
        md.append("## ðŸ“Š Resumo\n")
        s = report['summary']
        md.append(f"- **Issues Encontrados**: {s['total_issues']}")
        md.append(f"- **Issues CrÃ­ticos**: {s['critical_issues']} ðŸš¨")
        md.append(f"- **Descobertas Positivas**: {s['findings']}\n")
        
        # Issues crÃ­ticos
        critical = [i for i in report['issues'] if i['severity'] == 'critical']
        if critical:
            md.append("## ðŸš¨ ISSUES CRÃTICOS\n")
            for issue in critical:
                md.append(f"- **{issue['type']}**: {issue.get('file', 'N/A')}")
            md.append("")
            
        # RecomendaÃ§Ãµes
        if report['recommendations']:
            md.append("## ðŸ’¡ RECOMENDAÃ‡Ã•ES\n")
            for rec in sorted(report['recommendations'], key=lambda x: x['priority']):
                md.append(f"### {rec['priority']}: {rec['action']}")
                md.append(f"{rec['description']}\n")
                
        # Descobertas
        if report['findings']:
            md.append("## âœ… Descobertas Positivas\n")
            for finding in report['findings']:
                md.append(f"- {finding}")
                
        # Salvar
        with open(self.base_dir / 'DIAGNOSTICO_RESPOSTA_GENERICA.md', 'w', encoding='utf-8') as f:
            f.write('\n'.join(md))
            
    def run(self):
        """Executa diagnÃ³stico completo"""
        print("ðŸ” Diagnosticando Respostas GenÃ©ricas...\n")
        
        self.check_response_processor()
        self.check_data_flow()
        self.check_orchestrator_flow()
        self.check_analyzer_integration()
        self.check_config_loading()
        self.analyze_response_generation()
        
        report = self.generate_report()
        
        print("\n\nðŸ“Š DIAGNÃ“STICO FINAL:")
        print("=" * 60)
        s = report['summary']
        print(f"Issues: {s['total_issues']} (CrÃ­ticos: {s['critical_issues']})")
        
        if s['critical_issues'] > 0:
            print("\nðŸš¨ PROBLEMA IDENTIFICADO: O sistema nÃ£o estÃ¡ integrando com dados reais!")
            print("\nPRINCIPAIS CAUSAS:")
            for issue in report['issues']:
                if issue['severity'] == 'critical':
                    print(f"- {issue['type']}")
        else:
            print("\nâœ… Sistema parece estar configurado corretamente")
            
        print(f"\nðŸ“„ RelatÃ³rio salvo em: DIAGNOSTICO_RESPOSTA_GENERICA.md")

if __name__ == "__main__":
    diagnostic = GenericResponseDiagnostic()
    diagnostic.run() 