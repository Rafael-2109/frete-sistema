#!/usr/bin/env python3
"""
Script: generate_schemas.py
Gera automaticamente schemas JSON a partir dos modelos SQLAlchemy.

Produz:
  schemas/catalog.json          - Cat√°logo leve (nome + descri√ß√£o + key_fields) de TODAS tabelas
  schemas/tables/{table}.json   - Schema detalhado por tabela (campos, tipos, FKs, regras)
  schemas/relationships.json    - Mapa de ForeignKeys entre tabelas

Uso:
    cd /home/rafaelnascimento/projetos/frete_sistema
    source .venv/bin/activate
    python .claude/skills/consultando-sql/scripts/generate_schemas.py
    python .claude/skills/consultando-sql/scripts/generate_schemas.py --stats  # apenas estat√≠sticas
"""
import sys
import os
import json
import importlib
import inspect
import re
import argparse

# Adicionar raiz do projeto ao path
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../..'))
sys.path.insert(0, PROJECT_ROOT)

# Diret√≥rios de output
SCHEMAS_DIR = os.path.join(os.path.dirname(__file__), '..', 'schemas')
TABLES_DIR = os.path.join(SCHEMAS_DIR, 'tables')

# =====================================================================
# TABELAS BLOQUEADAS ‚Äî Nunca expor ao LLM
# =====================================================================
BLOCKED_TABLES = {
    # Auth / Permiss√µes
    'usuarios', 'permission_category', 'permission_module',
    'permission_submodule', 'user_permission', 'permission_template',
    'permission_cache', 'permission_log', 'batch_operation',
    'perfil_usuario', 'vendedor_permission', 'equipe_permission',
    # Agente
    'agent_sessions', 'agent_memories', 'agent_memory_versions',
    # Alembic
    'alembic_version',
    # Sess√µes web
    'portal_sessoes',
    # Tokens/OAuth
    'tagplus_oauth_token',
}

# =====================================================================
# TABELAS MORTAS ‚Äî 0 registros em produ√ß√£o (levantamento 2026-02-01)
# Exclu√≠das do cat√°logo para reduzir ru√≠do no prompt do LLM.
# Schemas detalhados N√ÉO s√£o gerados para estas tabelas.
# Reavalie periodicamente: se uma tabela ganhar dados, remova-a daqui.
# =====================================================================
DEAD_TABLES = {
    # BI (todas vazias)
    'bi_analise_regional', 'bi_despesa_detalhada', 'bi_frete_agregado',
    'bi_indicador_mensal', 'bi_performance_transportadora',
    # M√≥dulo MOTO (inteiro vazio)
    'cliente_moto', 'embarque_moto', 'empresa_venda_moto',
    'equipe_vendas_moto', 'modelo_moto', 'moto',
    'pedido_venda_moto', 'pedido_venda_moto_item',
    'transportadora_moto', 'vendedor_moto',
    # Financeiro fantasma (nunca populadas)
    'comissao_vendedor', 'custos_operacionais', 'despesa_mensal',
    'liberacao_antecipacao', 'movimentacao_financeira',
    'titulo_a_pagar', 'titulo_financeiro',
    # Carteira / Separa√ß√£o (vazias)
    'carteira_copia', 'controle_cruzado_separacao',
    'vinculacao_carteira_separacao',
    # Devolu√ß√µes (parcialmente mortas)
    'anexo_ocorrencia', 'contagem_devolucao',
    'descarte_devolucao', 'descarte_item', 'divergencia_fiscal',
    # Frete (vazias)
    'fretes_lancados', 'custos_extra_entrega',
    'tabela_preco_crossdocking', 'cross_docking',
    # Comercial/Vendas (nunca usadas)
    'equipe_vendas', 'vendedor', 'user_equipe', 'user_vendedor',
    'regra_comissao', 'tabela_preco_equipe',
    # Notifica√ß√µes/Webhooks (vazias)
    'alerta_notificacoes', 'webhook_configs',
    # Integra√ß√µes (vazias)
    'log_integracao', 'mapeamento_tipo_odoo',
    # Pedidos (fantasma ‚Äî 'pedidos' n√£o existe no banco, demais vazias)
    'pedidos', 'pedido_venda_auditoria', 'embarque_pedido',
    # Custos/Custeio (vazias)
    'custo_mensal',
    # Contas a receber (vazias)
    'contas_a_receber_abatimento', 'contas_a_receber_tipos',
    # Outros (0 registros)
    'lead_time_fornecedor', 'plano_mestre_producao',
    'portal_configuracoes', 'portal_tenda_agendamentos',
    'portal_tenda_local_entrega_depara', 'portal_tenda_produto_depara_ean',
    'tipo_carga', 'vale_pallets',
}

# =====================================================================
# TABELAS IRRELEVANTES PARA CONSULTAS ANAL√çTICAS
# T√™m dados em produ√ß√£o mas n√£o s√£o alvo de perguntas anal√≠ticas.
# Exclu√≠das para reduzir ru√≠do no cat√°logo do LLM.
# Revis√£o: 2026-02-01 (curadoria manual pelo usu√°rio)
# =====================================================================
IRRELEVANT_TABLES = {
    # Log√≠stica ‚Äî tabelas auxiliares/hist√≥rico sem valor anal√≠tico
    'alertas_separacao_cotada', 'pre_separacao_item',
    'historico_pedidos', 'historico_data_prevista',
    'faturamento_parcial_justificativa', 'inconsistencia_faturamento',
    'relatorio_faturamento_importado',
    # Fretes ‚Äî tabelas auxiliares (conta corrente, cota√ß√µes, hist√≥rico)
    'conta_corrente_transportadoras', 'cotacao_itens', 'cotacoes',
    'historico_tabelas_frete',
    # Financeiro ‚Äî lotes/headers (itens mantidos), logs, pend√™ncias
    'baixa_pagamento_lote', 'baixa_titulo_lote',
    'cnab_retorno_lote', 'extrato_lote',
    'pendencias_financeiras_nf', 'log_permissao_comercial',
    # Cadastros ‚Äî dados de cliente j√° est√£o em carteira/contas_a_receber
    'cadastro_cliente',
}

# =====================================================================
# TABELAS CORE ‚Äî Mantidas no schema.json manual com regras de neg√≥cio
# curadas √† m√£o. O cat√°logo referencia-as mas o schema detalhado
# delas vem do core_schema.json (o schema.json original renomeado).
# =====================================================================
CORE_TABLES = {
    'carteira_principal', 'separacao', 'movimentacao_estoque',
    'programacao_producao', 'cadastro_palletizacao', 'faturamento_produto',
    'embarques', 'embarque_itens', 'saldo_standby',
}

# =====================================================================
# MAPA DE DESCRI√á√ïES ‚Äî Descri√ß√µes curtas curadas para o cat√°logo
# Quando n√£o existe aqui, usa docstring da classe ou gera autom√°tico
# =====================================================================
TABLE_DESCRIPTIONS = {
    # Core (j√° no schema.json)
    'carteira_principal': 'Pedidos com saldo pendente. Fonte da verdade para demanda.',
    'separacao': 'Itens separados para expedi√ß√£o. Projeta sa√≠das de estoque.',
    'movimentacao_estoque': 'Movimentos de estoque: entradas, sa√≠das, ajustes, produ√ß√£o.',
    'programacao_producao': 'Produ√ß√£o programada por data e linha.',
    'cadastro_palletizacao': 'Cadastro de produtos com peso, pallet, convers√µes.',
    'faturamento_produto': 'NFs emitidas por produto. Registros de faturamento.',
    'embarques': 'Embarques que agrupam separa√ß√µes para transporte.',
    'embarque_itens': 'Itens individuais dentro de um embarque.',
    'saldo_standby': 'Pedidos em espera: saldo, comercial ou PCP.',
    # Financeiro
    'contas_a_receber': 'T√≠tulos a receber de clientes. Dados do Odoo enriquecidos.',
    'contas_a_receber_abatimento': 'Abatimentos aplicados a t√≠tulos a receber.',
    'contas_a_receber_tipos': 'Tipos de conta a receber (boleto, dep√≥sito, etc.).',
    'contas_a_receber_snapshot': 'Snapshots hist√≥ricos de contas a receber.',
    'contas_a_receber_reconciliacao': 'Reconcilia√ß√µes de contas a receber.',
    'contas_a_pagar': 'T√≠tulos a pagar para fornecedores.',
    'liberacao_antecipacao': 'Libera√ß√µes de antecipa√ß√£o de pagamento.',
    'mapeamento_tipo_odoo': 'Mapeamento de tipos de documento Odoo ‚Üí sistema.',
    'baixa_titulo_lote': 'Lotes de baixa de t√≠tulos a receber.',
    'baixa_titulo_item': 'Itens individuais de baixa de t√≠tulo.',
    'baixa_pagamento_lote': 'Lotes de pagamento para baixa.',
    'baixa_pagamento_item': 'Itens individuais de pagamento.',
    'extrato_lote': 'Lotes de extrato banc√°rio importados.',
    'extrato_item': 'Linhas individuais de extrato banc√°rio.',
    'extrato_item_titulo': 'V√≠nculo entre extrato banc√°rio e t√≠tulo.',
    'cnab_retorno_lote': 'Lotes de retorno CNAB banc√°rio.',
    'cnab_retorno_item': 'Itens individuais de retorno CNAB.',
    'pendencias_financeiras_nf': 'Pend√™ncias financeiras vinculadas a NFs.',
    'comprovante_pagamento_boleto': 'Comprovantes de pagamento de boletos.',
    'lancamento_comprovante': 'Lan√ßamentos de comprovantes financeiros.',
    'correcao_data_nf_credito': 'Corre√ß√µes de data de NFs de cr√©dito.',
    # Fretes
    'fretes': 'Fretes contratados para embarques. Valores e transportadoras.',
    'faturas_frete': 'Faturas de frete emitidas por transportadoras.',
    'despesas_extras': 'Despesas extras de frete (estadia, ped√°gio, etc.).',
    'conta_corrente_transportadoras': 'Conta corrente com transportadoras.',
    'aprovacoes_frete': 'Aprova√ß√µes de fretes por al√ßada.',
    'fretes_lancados': 'Fretes lan√ßados no Odoo.',
    'conhecimento_transporte': 'CT-es (Conhecimento de Transporte Eletr√¥nico).',
    # Devolu√ß√µes
    'nf_devolucao': 'NFs de devolu√ß√£o recebidas.',
    'nf_devolucao_linha': 'Linhas/itens de NF de devolu√ß√£o.',
    'nf_devolucao_nf_referenciada': 'NFs referenciadas em devolu√ß√µes.',
    'ocorrencia_devolucao': 'Ocorr√™ncias/motivos de devolu√ß√£o.',
    'frete_devolucao': 'Fretes de devolu√ß√µes.',
    'contagem_devolucao': 'Contagens de itens devolvidos.',
    'anexo_ocorrencia': 'Anexos de ocorr√™ncias (fotos, docs).',
    'depara_produto_cliente': 'De-Para de c√≥digo produto ‚Üî cliente.',
    'descarte_devolucao': 'Registros de descarte de devolu√ß√µes.',
    'descarte_item': 'Itens individuais de descarte.',
    # Recebimento
    'validacao_fiscal_dfe': 'Valida√ß√£o fiscal de DFe (NF-e entrada).',
    'validacao_nf_po_dfe': 'Match de NF de compra √ó PO no Odoo.',
    'match_nf_po_item': 'Itens do match NF √ó PO.',
    'match_nf_po_alocacao': 'Aloca√ß√£o de quantidades NF √ó PO.',
    'divergencia_nf_po': 'Diverg√™ncias encontradas NF √ó PO.',
    'divergencia_fiscal': 'Diverg√™ncias fiscais detectadas.',
    'perfil_fiscal_produto_fornecedor': 'Perfil fiscal produto √ó fornecedor.',
    'cadastro_primeira_compra': 'Cadastro de primeira compra.',
    'ncm_ibscbs_validado': 'NCMs validados contra IBSCBS.',
    'pendencia_fiscal_ibscbs': 'Pend√™ncias fiscais IBSCBS.',
    'produto_fornecedor_depara': 'De-Para produto √ó fornecedor.',
    'recebimento_fisico': 'Recebimentos f√≠sicos de materiais.',
    'recebimento_lote': 'Lotes de recebimento f√≠sico.',
    'recebimento_quality_check': 'Quality checks de recebimento.',
    'picking_recebimento': 'Pickings de recebimento (Odoo).',
    'picking_recebimento_produto': 'Produtos por picking de recebimento.',
    'picking_recebimento_move_line': 'Move lines de picking de recebimento.',
    'picking_recebimento_quality_check': 'Quality checks de picking.',
    # Rastreamento
    'rastreamento_embarques': 'Rastreamento GPS de embarques.',
    'pings_gps': 'Pings GPS de ve√≠culos.',
    'logs_rastreamento': 'Logs de rastreamento.',
    'configuracao_rastreamento': 'Configura√ß√µes de rastreamento.',
    'entregas_rastreadas': 'Entregas com rastreamento ativo.',
    'entregas_monitoradas': 'Monitoramento de entregas com status e ocorr√™ncias.',
    'agendamentos_entrega': 'Agendamentos de entrega.',
    'eventos_entrega': 'Eventos de entrega (tentativa, sucesso, falha).',
    'custos_extra_entrega': 'Custos extras de entrega.',
    'logs_entrega': 'Logs de entrega.',
    'comentarios_nf': 'Coment√°rios em notas fiscais.',
    'historico_data_prevista': 'Hist√≥rico de datas previstas.',
    'arquivo_entrega': 'Arquivos anexados a entregas.',
    # Cota√ß√£o
    'cotacoes': 'Cota√ß√µes de frete para embarques.',
    'cotacao_itens': 'Itens de cota√ß√£o de frete.',
    # Transportadoras
    'transportadoras': 'Cadastro de transportadoras com dados log√≠sticos e financeiros.',
    'veiculos': 'Frota de ve√≠culos por transportadora.',
    'cidades_atendidas': 'Cidades atendidas por transportadora com lead time.',
    # Localidades
    'cidades': 'Cadastro de cidades do Brasil.',
    'cadastro_rota': 'Cadastro de rotas log√≠sticas por UF.',
    'cadastro_sub_rota': 'Sub-rotas por cidade.',
    # Estoque
    'unificacao_codigos': 'Unifica√ß√£o de c√≥digos de produto.',
    'grupo_empresarial': 'Grupos empresariais.',
    # Faturamento extra
    'relatorio_faturamento_importado': 'Relat√≥rios de faturamento importados.',
    'inconsistencia_faturamento': 'Inconsist√™ncias encontradas no faturamento.',
    'faturamento_parcial_justificativa': 'Justificativas de faturamento parcial.',
    # Pedidos
    'pedidos': 'Pedidos do TagPlus importados.',
    'cadastro_cliente': 'Cadastro de clientes.',
    'pre_separacao_item': 'Itens de pr√©-separa√ß√£o.',
    'controle_cruzado_separacao': 'Controle cruzado de separa√ß√µes.',
    # Carteira
    'carteira_copia': 'C√≥pia de seguran√ßa da carteira.',
    # Portaria
    'motoristas': 'Cadastro de motoristas.',
    'controle_portaria': 'Controle de entrada/sa√≠da na portaria.',
    # Notifica√ß√µes
    'alerta_notificacoes': 'Alertas e notifica√ß√µes do sistema.',
    'webhook_configs': 'Configura√ß√µes de webhooks.',
    # BI
    'bi_frete_agregado': 'BI: fretes agregados por per√≠odo.',
    'bi_despesa_detalhada': 'BI: despesas detalhadas.',
    'bi_performance_transportadora': 'BI: performance de transportadoras.',
    'bi_analise_regional': 'BI: an√°lise regional de fretes.',
    'bi_indicador_mensal': 'BI: indicadores mensais.',
    # Tabelas de pre√ßo/frete
    'tabelas_frete': 'Tabelas de pre√ßo de frete.',
    'historico_tabelas_frete': 'Hist√≥rico de tabelas de frete.',
    # Custeio
    'custo_mensal': 'Custos mensais operacionais.',
    'custo_considerado': 'Custos considerados para an√°lise.',
    'custo_frete': 'Custos de frete calculados.',
    'parametro_custeio': 'Par√¢metros de custeio.',
    # Comercial
    'permissao_comercial': 'Permiss√µes comerciais por vendedor.',
    'log_permissao_comercial': 'Logs de permiss√µes comerciais.',
    # Alertas
    'alertas_separacao_cotada': 'Alertas de separa√ß√µes cotadas.',
    # Email
    'emails_anexados': 'Emails anexados a documentos.',
    # Valida√ß√£o pedidos
    'tabela_rede_precos': 'Tabela de pre√ßos por rede.',
    'regiao_tabela_rede': 'Regi√µes por tabela de rede.',
    # Integra√ß√µes Odoo
    'registro_pedido_odoo': 'Registro de pedidos enviados ao Odoo.',
    'pedido_importacao_temp': 'Pedidos tempor√°rios para importa√ß√£o.',
    'lancamento_frete_odoo_auditoria': 'Auditoria de lan√ßamentos de frete no Odoo.',
    # Contatos
    'contatos_agendamento': 'Contatos para agendamento de entrega.',
    # Vendedores / Equipes
    'vendedor': 'Cadastro de vendedores.',
    'equipe_vendas': 'Equipes de vendas.',
    'user_vendedor': 'V√≠nculo usu√°rio ‚Üî vendedor.',
    'user_equipe': 'V√≠nculo usu√°rio ‚Üî equipe.',
    # Log integra√ß√£o
    'log_integracao': 'Logs de integra√ß√µes com sistemas externos.',
    # NF TagPlus
    'nf_pendente_tagplus': 'NFs pendentes no TagPlus.',
}


# =====================================================================
# FUN√á√ïES DE EXTRA√á√ÉO
# =====================================================================

def get_sqlalchemy_type_str(col_type) -> str:
    """Converte tipo SQLAlchemy para string leg√≠vel."""
    type_name = type(col_type).__name__

    type_map = {
        'String': lambda t: f"varchar({t.length})" if t.length else "varchar",
        'Integer': lambda t: "integer",
        'BigInteger': lambda t: "bigint",
        'SmallInteger': lambda t: "smallint",
        'Float': lambda t: "float",
        'Numeric': lambda t: f"numeric({t.precision},{t.scale})" if t.precision else "numeric",
        'Boolean': lambda t: "boolean",
        'Text': lambda t: "text",
        'Date': lambda t: "date",
        'DateTime': lambda t: "timestamp",
        'Time': lambda t: "time",
        'JSON': lambda t: "json",
        'LargeBinary': lambda t: "bytea",
        'Enum': lambda t: f"enum({','.join(t.enums)})" if hasattr(t, 'enums') else "enum",
    }

    converter = type_map.get(type_name)
    if converter:
        try:
            return converter(col_type)
        except Exception:
            return type_name.lower()

    return type_name.lower()


def _clean_description(desc: str) -> str:
    """
    Limpa uma descri√ß√£o extra√≠da do source code.
    Remove emojis, marcadores de debug, separadores visuais, etc.
    Retorna string vazia se a descri√ß√£o n√£o tiver valor informativo.
    """
    if not desc:
        return ""

    # Limpar emojis unicode (‚úÖüìãüîç‚≠êüÜîüë•üì¶üìäüí∞üè∑Ô∏èüí≥üè†üìÖüîÑüóëÔ∏èüì∏üõ°Ô∏è‚Üê‚Üí etc.)
    desc = re.sub(
        r'[\U0001F000-\U0001FFFF'   # Supplemental Symbols
        r'\u2190-\u21FF'             # Arrows (‚Üê‚Üí‚Üë‚Üì)
        r'\u2600-\u27BF'             # Misc Symbols + Dingbats
        r'\u2B50\u2705\u26A0'        # Star, Check, Warning
        r'\u2714\u2716\u2728'        # Check, X, Sparkles
        r'\u274C\u274E'              # Cross marks
        r']+\s*', '', desc
    )

    # Separadores visuais (===, ----, ****)
    if re.match(r'^[=\-*_]{3,}', desc):
        return ""

    # Marcadores de debug (<--- AQUI, TODO, FIXME, HACK, XXX)
    if re.search(r'<-{2,}|TODO\b|FIXME\b|HACK\b|XXX\b', desc, re.IGNORECASE):
        return ""

    # T√≠tulos de se√ß√£o ALL-CAPS puros (ex: "DADOS DO PEDIDO", "CAMPOS DE VALOR")
    if re.match(r'^[A-Z√Å√â√ç√ì√ö√Ç√ä√î\s]{5,}$', desc):
        return ""

    # Prefixos ALL-CAPS sem valor informativo (patterns mais longos primeiro)
    desc = re.sub(
        r'^(NOVOS?\s+CAMPOS?\s*(?:DE\s+\w+)?|NOVO|ADICIONADO|REMOVIDO|ALTERADO)\s*:?\s*',
        '', desc, flags=re.IGNORECASE
    )

    # Metadata t√©cnica (Constraint, Index, Unique, Migration)
    if re.match(r'^(Constraint|Index|Unique|Migration|FK\s|PK\s)', desc, re.IGNORECASE):
        return ""

    desc = desc.strip()
    if desc and len(desc) > 3:
        return desc[:120]
    return ""


def extract_field_description(model_class, field_name: str) -> str:
    """
    Tenta extrair descri√ß√£o do campo a partir de:
    1. info dict do Column
    2. doc/comment do Column
    3. Coment√°rio inline no source code (processado linha por linha)
    """
    # Tentar info dict
    col = model_class.__table__.columns.get(field_name)
    if col is not None:
        info = getattr(col, 'info', {})
        if isinstance(info, dict) and 'description' in info:
            return _clean_description(info['description'])

        comment = getattr(col, 'comment', None)
        if comment:
            return _clean_description(comment)

    # Tentar extrair coment√°rio inline do source code (LINHA POR LINHA)
    try:
        source = inspect.getsource(model_class)
        # Processar linha por linha para evitar cruzar newlines
        # BUG FIX: \s* no regex antigo cruzava \n, capturando headers de se√ß√£o
        for line in source.splitlines():
            # Procurar: field_name = db.Column(...) # Descri√ß√£o
            # Word boundary ((?<![a-zA-Z_])) evita match parcial
            # ex: 'cliente' n√£o matcha em 'qtd_pallet_cliente'
            pattern = rf'(?<![a-zA-Z_]){re.escape(field_name)}\s*=\s*db\.Column\([^)]*\)[^\n#]*#\s*(.+)'
            match = re.search(pattern, line)
            if match:
                desc = _clean_description(match.group(1).strip())
                if desc:
                    return desc
    except (TypeError, OSError):
        pass

    return ""


def extract_class_docstring(model_class) -> str:
    """Extrai docstring da classe do modelo."""
    doc = inspect.getdoc(model_class)
    if doc:
        # Primeira linha significativa
        for line in doc.split('\n'):
            line = line.strip()
            if line and len(line) > 10:
                return line[:200]
    return ""


def extract_table_schema(table_name: str, table, model_class=None) -> dict:
    """Extrai schema detalhado de uma tabela SQLAlchemy."""
    fields = []
    foreign_keys = []

    for col in table.columns:
        field = {
            'name': col.name,
            'type': get_sqlalchemy_type_str(col.type),
        }

        # Descri√ß√£o
        desc = ""
        if col.primary_key:
            # Primary key sempre tem descri√ß√£o fixa
            desc = "Primary key"
        elif model_class:
            desc = extract_field_description(model_class, col.name)
        if not desc:
            # Gerar descri√ß√£o autom√°tica
            if col.name.endswith('_id') and col.foreign_keys:
                fk = list(col.foreign_keys)[0]
                desc = f"FK ‚Üí {fk.column.table.name}.{fk.column.name}"
            elif col.name in ('created_at', 'criado_em'):
                desc = "Data de cria√ß√£o"
            elif col.name in ('updated_at', 'atualizado_em'):
                desc = "√öltima atualiza√ß√£o"
            elif col.name == 'ativo':
                desc = "True = registro ativo"
        if desc:
            field['description'] = desc

        # Nullable
        if not col.nullable and not col.primary_key:
            field['nullable'] = False

        # Default
        if col.default is not None:
            default_val = col.default
            if hasattr(default_val, 'arg'):
                arg = default_val.arg
                if isinstance(arg, (str, int, float, bool)):
                    field['default'] = arg

        fields.append(field)

        # Foreign keys
        for fk in col.foreign_keys:
            foreign_keys.append({
                'column': col.name,
                'references': f"{fk.column.table.name}.{fk.column.name}"
            })

    # Descri√ß√£o da tabela
    description = TABLE_DESCRIPTIONS.get(table_name, "")
    if not description and model_class:
        description = extract_class_docstring(model_class)
    if not description:
        description = f"Tabela {table_name}"

    # Unique constraints
    unique_constraints = []
    for constraint in table.constraints:
        from sqlalchemy import UniqueConstraint
        if isinstance(constraint, UniqueConstraint) and constraint.columns:
            cols = [c.name for c in constraint.columns]
            if len(cols) > 1:  # S√≥ compostos
                unique_constraints.append(cols)

    # √çndices
    indices = []
    for idx in table.indexes:
        cols = [c.name for c in idx.columns]
        if cols:
            indices.append({
                'name': idx.name,
                'columns': cols,
                'unique': idx.unique
            })

    schema = {
        'name': table_name,
        'description': description,
        'fields': fields,
    }

    if foreign_keys:
        schema['foreign_keys'] = foreign_keys
    if unique_constraints:
        schema['unique_constraints'] = unique_constraints
    if indices:
        schema['indices'] = indices

    return schema


def generate_catalog_entry(table_name: str, table, model_class=None) -> dict:
    """Gera entrada leve do cat√°logo: nome + descri√ß√£o + 3 campos-chave."""
    description = TABLE_DESCRIPTIONS.get(table_name, "")
    if not description and model_class:
        description = extract_class_docstring(model_class)
    if not description:
        description = f"Tabela {table_name}"

    # Selecionar 3 campos-chave (excluindo id, created_at, etc.)
    skip_fields = {'id', 'created_at', 'updated_at', 'criado_em', 'atualizado_em', 'ativo'}
    key_fields = []
    for col in table.columns:
        if col.name in skip_fields:
            continue
        if col.primary_key:
            continue
        key_fields.append(col.name)
        if len(key_fields) >= 3:
            break

    return {
        'name': table_name,
        'description': description,
        'key_fields': key_fields,
    }


def extract_relationships(metadata) -> list:
    """Extrai relacionamentos FK entre tabelas."""
    relationships = []
    seen = set()

    for table_name, table in sorted(metadata.tables.items()):
        if table_name in BLOCKED_TABLES:
            continue

        for col in table.columns:
            for fk in col.foreign_keys:
                ref_table = fk.column.table.name
                if ref_table in BLOCKED_TABLES:
                    continue

                key = f"{table_name}.{col.name}->{ref_table}.{fk.column.name}"
                if key not in seen:
                    seen.add(key)
                    relationships.append({
                        'from_table': table_name,
                        'from_column': col.name,
                        'to_table': ref_table,
                        'to_column': fk.column.name,
                    })

    return relationships


# =====================================================================
# IMPORTA√á√ÉO DOS MODELOS
# =====================================================================

def import_all_models():
    """Importa todos os modelos SQLAlchemy e retorna metadata + model_map."""

    # Importar app para inicializar SQLAlchemy metadata
    os.environ.setdefault('FLASK_ENV', 'development')

    from app import create_app, db

    app = create_app()

    with app.app_context():
        # Modelo -> tabela mapping
        model_map = {}  # table_name -> model_class

        # Importar todos os m√≥dulos de modelos
        model_modules = [
            'app.agente.models',
            'app.auth.models',
            'app.bi.models',
            'app.cadastros_agendamento.models',
            'app.carteira.models',
            'app.carteira.models_alertas',
            'app.comercial.models',
            'app.cotacao.models',
            'app.custeio.models',
            'app.devolucao.models',
            'app.embarques.models',
            'app.estoque.models',
            'app.faturamento.models',
            'app.financeiro.models',
            'app.financeiro.models_comprovante',
            'app.financeiro.models_correcao_datas',
            'app.fretes.email_models',
            'app.fretes.models',
            'app.integracoes.tagplus.models',
            'app.localidades.models',
            'app.manufatura.models',
            'app.monitoramento.models',
            'app.motochefe.models.cadastro',
            'app.motochefe.models.financeiro',
            'app.motochefe.models.logistica',
            'app.motochefe.models.operacional',
            'app.motochefe.models.produto',
            'app.motochefe.models.vendas',
            'app.notificacoes.models',
            'app.pallet.models.credito',
            'app.pallet.models.documento',
            'app.pallet.models.nf_remessa',
            'app.pallet.models.nf_solucao',
            'app.pallet.models.solucao',
            'app.pallet.models.vale_pallet',
            'app.pedidos.integracao_odoo.models',
            'app.pedidos.models',
            'app.pedidos.validacao.models',
            'app.permissions.models',
            'app.portal.atacadao.models',
            'app.portal.models',
            'app.portal.models_fila_sendas',
            'app.portal.sendas.models',
            'app.portal.sendas.models_planilha',
            'app.portal.tenda.models',
            'app.portaria.models',
            'app.producao.models',
            'app.rastreamento.models',
            'app.recebimento.models',
            'app.separacao.models',
            'app.tabelas.models',
            'app.transportadoras.models',
            'app.veiculos.models',
            'app.vinculos.models',
        ]

        for module_name in model_modules:
            try:
                mod = importlib.import_module(module_name)

                # Mapear classes que s√£o db.Model
                for name, obj in inspect.getmembers(mod, inspect.isclass):
                    if hasattr(obj, '__tablename__') and hasattr(obj, '__table__'):
                        table_name = obj.__tablename__
                        model_map[table_name] = obj

            except Exception as e:
                print(f"‚ö†Ô∏è  Erro ao importar {module_name}: {e}")

        return db.metadata, model_map


# =====================================================================
# GERA√á√ÉO DOS ARQUIVOS
# =====================================================================

def generate_all(stats_only=False):
    """Gera todos os schemas."""
    print("üîç Importando modelos SQLAlchemy...")
    metadata, model_map = import_all_models()

    all_tables = sorted(metadata.tables.keys())
    excluded = BLOCKED_TABLES | DEAD_TABLES | IRRELEVANT_TABLES
    allowed_tables = [t for t in all_tables if t not in excluded]
    blocked = [t for t in all_tables if t in BLOCKED_TABLES]
    dead = [t for t in all_tables if t in DEAD_TABLES]
    irrelevant = [t for t in all_tables if t in IRRELEVANT_TABLES]

    print(f"\nüìä Estat√≠sticas:")
    print(f"   Total de tabelas no metadata: {len(all_tables)}")
    print(f"   Tabelas bloqueadas (auth/agent): {len(blocked)}")
    print(f"   Tabelas mortas (0 registros): {len(dead)}")
    print(f"   Tabelas irrelevantes (curadoria manual): {len(irrelevant)}")
    print(f"   Tabelas permitidas: {len(allowed_tables)}")
    print(f"   Tabelas core (schema manual): {len(CORE_TABLES)}")
    print(f"   Tabelas para schema auto-gerado: {len(allowed_tables) - len(CORE_TABLES)}")
    print(f"   Models com classe Python mapeada: {len(model_map)}")

    if stats_only:
        print(f"\nüìã Tabelas bloqueadas (auth/agent):")
        for t in sorted(blocked):
            print(f"   ‚ùå {t}")
        print(f"\nüìã Tabelas mortas (0 registros):")
        for t in sorted(dead):
            print(f"   üíÄ {t}")
        print(f"\nüìã Tabelas irrelevantes (curadoria manual):")
        for t in sorted(irrelevant):
            print(f"   üö´ {t}")
        print(f"\nüìã Tabelas core (schema.json manual):")
        for t in sorted(CORE_TABLES):
            print(f"   ‚≠ê {t}")
        print(f"\nüìã Tabelas n√£o-core permitidas:")
        for t in sorted(allowed_tables):
            if t not in CORE_TABLES:
                desc = TABLE_DESCRIPTIONS.get(t, "sem descri√ß√£o")
                has_model = "‚úÖ" if t in model_map else "‚ùì"
                print(f"   {has_model} {t}: {desc}")
        return

    # Garantir diret√≥rios
    os.makedirs(TABLES_DIR, exist_ok=True)

    # 1. Gerar schemas individuais por tabela
    print(f"\nüìù Gerando schemas individuais...")
    tables_generated = 0
    for table_name in allowed_tables:
        table = metadata.tables[table_name]
        model_class = model_map.get(table_name)

        schema = extract_table_schema(table_name, table, model_class)

        output_path = os.path.join(TABLES_DIR, f"{table_name}.json")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(schema, f, ensure_ascii=False, indent=2)

        tables_generated += 1

    print(f"   ‚úÖ {tables_generated} schemas gerados em schemas/tables/")

    # 2. Gerar cat√°logo
    print(f"\nüìù Gerando cat√°logo...")
    catalog = {
        'version': '2.0.0',
        'database': 'postgresql',
        'notas_gerais': [
            'Todos os valores monet√°rios em BRL (R$)',
            'Datas no formato YYYY-MM-DD no banco',
            'Campos Boolean: True/False (PostgreSQL)',
            'Registros ativos: ativo = True (quando o campo existe)',
            'Para usar campos detalhados, consultar schemas/tables/{tabela}.json'
        ],
        'tabelas_bloqueadas': sorted(BLOCKED_TABLES | DEAD_TABLES | IRRELEVANT_TABLES),
        'total_tabelas': len(allowed_tables),
        'tabelas': []
    }

    for table_name in allowed_tables:
        table = metadata.tables[table_name]
        model_class = model_map.get(table_name)
        entry = generate_catalog_entry(table_name, table, model_class)
        catalog['tabelas'].append(entry)

    catalog_path = os.path.join(SCHEMAS_DIR, 'catalog.json')
    with open(catalog_path, 'w', encoding='utf-8') as f:
        json.dump(catalog, f, ensure_ascii=False, indent=2)

    catalog_size = os.path.getsize(catalog_path)
    print(f"   ‚úÖ catalog.json gerado ({catalog_size:,} bytes, {len(catalog['tabelas'])} tabelas)")

    # 3. Gerar relationships
    print(f"\nüìù Gerando mapa de relacionamentos...")
    relationships = extract_relationships(metadata)

    rel_data = {
        'version': '2.0.0',
        'total_relationships': len(relationships),
        'relationships': relationships,
    }

    rel_path = os.path.join(SCHEMAS_DIR, 'relationships.json')
    with open(rel_path, 'w', encoding='utf-8') as f:
        json.dump(rel_data, f, ensure_ascii=False, indent=2)

    print(f"   ‚úÖ relationships.json gerado ({len(relationships)} FKs)")

    # 4. Resumo final
    total_fields = sum(
        len(metadata.tables[t].columns) for t in allowed_tables
    )
    print(f"\n{'='*60}")
    print(f"‚úÖ GERA√á√ÉO COMPLETA")
    print(f"   Tabelas: {len(allowed_tables)}")
    print(f"   Campos totais: {total_fields}")
    print(f"   Relacionamentos: {len(relationships)}")
    print(f"   Arquivos gerados:")
    print(f"      schemas/catalog.json ({catalog_size:,} bytes)")
    print(f"      schemas/relationships.json")
    print(f"      schemas/tables/*.json ({tables_generated} arquivos)")
    print(f"{'='*60}")


# =====================================================================
# MAIN
# =====================================================================

def main():
    parser = argparse.ArgumentParser(
        description='Gera schemas JSON a partir dos modelos SQLAlchemy'
    )
    parser.add_argument(
        '--stats', action='store_true',
        help='Apenas mostrar estat√≠sticas, sem gerar arquivos'
    )
    args = parser.parse_args()

    generate_all(stats_only=args.stats)


if __name__ == '__main__':
    main()
