#!/usr/bin/env python3
"""
ğŸ§ª TESTE DAS CORREÃ‡Ã•ES CRÃTICAS APLICADAS
=========================================

Testa se as correÃ§Ãµes manuais que aplicamos resolveram os erros crÃ­ticos
que apareciam nos logs de produÃ§Ã£o.

CORREÃ‡Ã•ES TESTADAS:
1. âŒ object dict can't be used in 'await' expression
2. âŒ QueryProcessor.__init__() missing 3 required positional arguments
3. âš ï¸ SemanticValidator/CriticValidator requer orchestrator
"""

import sys
import logging
from datetime import datetime

# Configurar logging para capturar erros
logging.basicConfig(level=logging.DEBUG, format='%(levelname)s:%(name)s:%(message)s')

def teste_integration_manager_await():
    """
    TESTE 1: Verifica se erro de await foi corrigido
    âŒ object dict can't be used in 'await' expression
    """
    print("ğŸ§ª TESTE 1: Integration Manager - Erro de await")
    print("-" * 50)
    
    try:
        from app.claude_ai_novo.integration.integration_manager import get_integration_manager
        
        # Instanciar manager
        manager = get_integration_manager()
        print("âœ… IntegrationManager instanciado com sucesso")
        
        # Testar mÃ©todo que causava erro
        if hasattr(manager, 'process_unified_query'):
            print("âœ… MÃ©todo process_unified_query existe")
            # NÃ£o vamos chamar assÃ­ncrono aqui, sÃ³ verificar que existe
            return True
        else:
            print("âŒ MÃ©todo process_unified_query nÃ£o encontrado")
            return False
            
    except Exception as e:
        print(f"âŒ Erro no teste: {e}")
        return False

def teste_query_processor_argumentos():
    """
    TESTE 2: Verifica se argumentos do QueryProcessor foram corrigidos
    âŒ QueryProcessor.__init__() missing 3 required positional arguments
    """
    print("\nğŸ§ª TESTE 2: QueryProcessor - Argumentos obrigatÃ³rios")
    print("-" * 50)
    
    resultados = []
    
    # Teste 2A: processors/__init__.py
    try:
        from app.claude_ai_novo.processors import get_query_processor
        
        processor = get_query_processor()
        if processor:
            print("âœ… QueryProcessor via processors/__init__.py - OK")
            resultados.append(True)
        else:
            print("âš ï¸ QueryProcessor via processors/__init__.py - None retornado")
            resultados.append(False)
            
    except Exception as e:
        print(f"âŒ Erro em processors/__init__.py: {e}")
        resultados.append(False)
    
    # Teste 2B: utils/processor_registry.py
    try:
        from app.claude_ai_novo.utils.processor_registry import get_processor_registry
        
        registry = get_processor_registry()
        query_processor = registry.get_processor('query')
        
        if query_processor:
            print("âœ… QueryProcessor via ProcessorRegistry - OK")
            resultados.append(True)
        else:
            print("âš ï¸ QueryProcessor via ProcessorRegistry - None retornado")
            resultados.append(False)
            
    except Exception as e:
        print(f"âŒ Erro em ProcessorRegistry: {e}")
        resultados.append(False)
    
    return all(resultados)

def teste_validators_warnings():
    """
    TESTE 3: Verifica se warnings dos validators foram corrigidos
    âš ï¸ SemanticValidator/CriticValidator requer orchestrator
    """
    print("\nğŸ§ª TESTE 3: Validators - Warnings de orchestrator")
    print("-" * 50)
    
    try:
        # Capturar logs de warning
        import io
        from contextlib import redirect_stderr
        
        log_capture = io.StringIO()
        
        # Configurar handler para capturar logs
        logger = logging.getLogger('app.claude_ai_novo.validators.validator_manager')
        
        # Importar e instanciar
        from app.claude_ai_novo.validators.validator_manager import get_validator_manager
        
        # Capturar warnings durante inicializaÃ§Ã£o
        with redirect_stderr(log_capture):
            validator_manager = get_validator_manager()
        
        # Verificar se foi instanciado
        if validator_manager:
            print("âœ… ValidatorManager instanciado com sucesso")
            
            # Verificar se temos warnings crÃ­ticos nos logs
            logs_captured = log_capture.getvalue()
            
            # Estes warnings NÃƒO devem mais aparecer
            problematic_warnings = [
                "âš ï¸ SemanticValidator requer orchestrator",
                "âš ï¸ CriticValidator requer orchestrator"
            ]
            
            warnings_found = []
            for warning in problematic_warnings:
                if warning in logs_captured:
                    warnings_found.append(warning)
            
            if warnings_found:
                print(f"âŒ Ainda hÃ¡ warnings problemÃ¡ticos: {warnings_found}")
                return False
            else:
                print("âœ… Warnings problemÃ¡ticos removidos")
                return True
        else:
            print("âŒ ValidatorManager nÃ£o pÃ´de ser instanciado")
            return False
            
    except Exception as e:
        print(f"âŒ Erro no teste: {e}")
        return False

def teste_novos_erros():
    """
    TESTE 4: Verifica se hÃ¡ novos erros crÃ­ticos
    Testa erros que apareceram nos logs alÃ©m dos que corrigimos
    """
    print("\nğŸ§ª TESTE 4: Verificar novos erros crÃ­ticos")
    print("-" * 50)
    
    novos_erros = []
    
    # Teste 4A: SpecialistAgent agent_type
    try:
        from app.claude_ai_novo.coordinators.coordinator_manager import get_coordinator_manager
        
        coordinator = get_coordinator_manager()
        if coordinator:
            print("âœ… CoordinatorManager instanciado sem erro de SpecialistAgent")
        else:
            print("âš ï¸ CoordinatorManager retornou None")
            
    except Exception as e:
        if "agent_type" in str(e):
            print(f"âŒ NOVO ERRO: SpecialistAgent agent_type - {e}")
            novos_erros.append(f"SpecialistAgent: {e}")
        else:
            print(f"âš ï¸ Erro em CoordinatorManager: {e}")
    
    # Teste 4B: Commands modules
    try:
        from app.claude_ai_novo.commands import get_command_manager
        
        cmd_manager = get_command_manager()
        if cmd_manager:
            print("âœ… CommandManager carregado sem erros de mÃ³dulo")
        else:
            print("âš ï¸ CommandManager retornou None")
            
    except Exception as e:
        if "No module named" in str(e):
            print(f"âŒ NOVO ERRO: MÃ³dulo faltando - {e}")
            novos_erros.append(f"Module missing: {e}")
        else:
            print(f"âš ï¸ Erro em CommandManager: {e}")
    
    if novos_erros:
        print(f"\nâŒ {len(novos_erros)} novos erros encontrados")
        return False
    else:
        print("\nâœ… Nenhum novo erro crÃ­tico encontrado")
        return True

def main():
    """Executa todos os testes das correÃ§Ãµes"""
    print("ğŸ§ª TESTE DAS CORREÃ‡Ã•ES CRÃTICAS APLICADAS")
    print("=" * 60)
    print(f"Timestamp: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    print("=" * 60)
    
    testes = [
        ("Integration Manager (await error)", teste_integration_manager_await),
        ("QueryProcessor (argumentos)", teste_query_processor_argumentos),
        ("Validators (warnings)", teste_validators_warnings),
        ("Novos erros crÃ­ticos", teste_novos_erros)
    ]
    
    resultados = []
    
    for nome, teste_func in testes:
        try:
            resultado = teste_func()
            resultados.append((nome, resultado))
        except Exception as e:
            print(f"\nâŒ Erro crÃ­tico no teste '{nome}': {e}")
            resultados.append((nome, False))
    
    # RelatÃ³rio final
    print("\n" + "=" * 60)
    print("ğŸ“Š RELATÃ“RIO FINAL DOS TESTES")
    print("=" * 60)
    
    sucessos = 0
    total = len(resultados)
    
    for nome, sucesso in resultados:
        status = "âœ… PASSOU" if sucesso else "âŒ FALHOU"
        print(f"   {status} | {nome}")
        if sucesso:
            sucessos += 1
    
    print(f"\nğŸ“ˆ RESULTADO GERAL: {sucessos}/{total} testes passaram")
    
    if sucessos == total:
        print("ğŸ‰ TODAS AS CORREÃ‡Ã•ES FUNCIONARAM!")
        print("âœ… Sistema deve estar funcionando sem os erros crÃ­ticos")
        return True
    elif sucessos >= total * 0.8:
        print("ğŸŸ¡ MAIORIA DAS CORREÃ‡Ã•ES FUNCIONOU")
        print("âš ï¸ Alguns problemas menores podem persistir")
        return True
    else:
        print("ğŸ”´ CORREÃ‡Ã•ES NÃƒO FUNCIONARAM COMPLETAMENTE")
        print("âŒ Ainda hÃ¡ erros crÃ­ticos que precisam ser corrigidos")
        return False

if __name__ == "__main__":
    try:
        sucesso = main()
        sys.exit(0 if sucesso else 1)
    except Exception as e:
        print(f"\nğŸ’¥ ERRO CRÃTICO NO TESTE: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 